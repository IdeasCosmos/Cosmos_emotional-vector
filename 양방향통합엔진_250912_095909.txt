#!/usr/bin/env python3
"""
í†µí•©ëœ ì–‘ë°©í–¥ ê°ì •-ìŒì•… ì‹œìŠ¤í…œ
- ê¸°ì¡´ ì½”ë“œë“¤ì„ í†µí•©í•œ ì™„ì„±í˜• ì‹œìŠ¤í…œ
- ì‹¤ì‹œê°„ ì ì‘ í•™ìŠµ
- Up-Down/Down-Up ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©
- í•œêµ­ì–´ íŠ¹í™” ê°ì • ë¶„ì„
- ìŒì•…ì  í‘œí˜„ ë³€í™˜
"""

import numpy as np
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field
from collections import deque
import json

# =============================================================================
# 1. í†µí•© ë°ì´í„° êµ¬ì¡°
# =============================================================================

@dataclass
class EmotionVector:
    """28ì°¨ì› ê°ì • ë²¡í„°"""
    amplitude: np.ndarray      # 0-7: ê°ì • ê°•ë„
    phase: np.ndarray         # 8-15: ê´€ê³„ì„±
    emotion_components: np.ndarray  # 16-21: ê°ì • ì„±ë¶„
    consistency: np.ndarray    # 22-27: ì¼ê´€ì„±

@dataclass
class SystemMemory:
    """ì‹œìŠ¤í…œ í•™ìŠµ ê¸°ì–µ"""
    experiences: deque = field(default_factory=lambda: deque(maxlen=1000))
    weights_history: deque = field(default_factory=lambda: deque(maxlen=100))
    performance_history: deque = field(default_factory=lambda: deque(maxlen=500))

@dataclass
class AnalysisResult:
    """í†µí•© ë¶„ì„ ê²°ê³¼"""
    emotion_vector: EmotionVector
    hierarchical_analysis: Dict
    music_expression: Dict
    confidence_score: float
    processing_time: float
    adaptation_metadata: Dict

# =============================================================================
# 2. í•µì‹¬ í†µí•© ì‹œìŠ¤í…œ
# =============================================================================

class UnifiedBidirectionalSystem:
    """
    í†µí•©ëœ ì–‘ë°©í–¥ ê°ì •-ìŒì•… ì‹œìŠ¤í…œ
    
    í•µì‹¬ ê¸°ëŠ¥:
    1. ì‹¤ì‹œê°„ ì ì‘ í•™ìŠµ
    2. ê³„ì¸µì  ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©
    3. í•œêµ­ì–´ íŠ¹í™” ê°ì • ë¶„ì„
    4. ìŒì•…ì  í‘œí˜„ ë³€í™˜
    5. ìê°€ ìµœì í™”
    """
    
    def __init__(self):
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
        self.memory = SystemMemory()
        
        # ë™ì  ê°€ì¤‘ì¹˜ (ê³„ì¸µë³„ ì¤‘ìš”ë„)
        self.dynamic_weights = {
            'morpheme': 0.15,    # í˜•íƒœì†Œ
            'word': 0.25,        # ë‹¨ì–´
            'phrase': 0.20,      # êµ¬ë¬¸
            'sentence': 0.25,    # ë¬¸ì¥
            'discourse': 0.15    # ë‹´í™”
        }
        
        # ìƒí˜¸ì‘ìš© ê°€ì¤‘ì¹˜ (Up-Down vs Down-Up)
        self.interaction_weights = {
            'up_down_strength': 0.4,      # ë‹´í™”â†’í˜•íƒœì†Œ (í•˜í–¥)
            'down_up_strength': 0.4,      # í˜•íƒœì†Œâ†’ë‹´í™” (ìƒí–¥)
            'cross_layer_correlation': 0.2 # êµì°¨ ê³„ì¸µ
        }
        
        # í•™ìŠµ íŒŒë¼ë¯¸í„°
        self.learning_rate = 0.01
        self.adaptation_speed = 0.05
        self.learning_active = True
        
        # í•œêµ­ì–´ íŠ¹í™” ê°ì • ì‚¬ì „
        self.korean_emotions = self._initialize_korean_emotions()
        
        # ìŒì•… ë³€í™˜ ì—”ì§„
        self.music_templates = self._initialize_music_templates()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_metrics = {
            'total_analyses': 0,
            'accuracy_trend': [],
            'adaptation_rate': 0.0
        }
    
    def analyze_emotion_to_music(self, text: str, user_feedback: Optional[Dict] = None) -> AnalysisResult:
        """
        ë©”ì¸ ë¶„ì„ í•¨ìˆ˜: í…ìŠ¤íŠ¸ â†’ ê°ì • â†’ ìŒì•…
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            user_feedback: ì‚¬ìš©ì í”¼ë“œë°± (ì •í™•ë„, ì„ í˜¸ë„ ë“±)
        
        Returns:
            AnalysisResult: í†µí•© ë¶„ì„ ê²°ê³¼
        """
        start_time = time.time()
        
        # 1. ê³„ì¸µì  ê°ì • ë¶„ì„
        hierarchical_analysis = self._analyze_hierarchical(text)
        
        # 2. ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© ì²˜ë¦¬
        bidirectional_effects = self._process_bidirectional_interactions(hierarchical_analysis)
        
        # 3. 28ì°¨ì› ê°ì • ë²¡í„° ìƒì„±
        emotion_vector = self._generate_emotion_vector(hierarchical_analysis, bidirectional_effects)
        
        # 4. ìŒì•… í‘œí˜„ ë³€í™˜
        music_expression = self._convert_to_music(emotion_vector)
        
        # 5. ì‹¤ì‹œê°„ í•™ìŠµ (í”¼ë“œë°±ì´ ìˆì„ ë•Œ)
        adaptation_metadata = {}
        if user_feedback and self.learning_active:
            adaptation_metadata = self._perform_real_time_learning(
                hierarchical_analysis, emotion_vector, music_expression, user_feedback
            )
        
        # 6. ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = self._calculate_confidence(hierarchical_analysis, bidirectional_effects)
        
        # 7. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self._update_performance_metrics(confidence_score, user_feedback)
        
        processing_time = time.time() - start_time
        
        return AnalysisResult(
            emotion_vector=emotion_vector,
            hierarchical_analysis=hierarchical_analysis,
            music_expression=music_expression,
            confidence_score=confidence_score,
            processing_time=processing_time,
            adaptation_metadata=adaptation_metadata
        )
    
    def _analyze_hierarchical(self, text: str) -> Dict:
        """ê³„ì¸µì  ê°ì • ë¶„ì„"""
        
        # í˜•íƒœì†Œ ë¶„ì„
        morpheme_result = self._analyze_morphemes(text)
        
        # ë‹¨ì–´ ë¶„ì„
        word_result = self._analyze_words(text)
        
        # êµ¬ë¬¸ ë¶„ì„
        phrase_result = self._analyze_phrases(text)
        
        # ë¬¸ì¥ ë¶„ì„
        sentence_result = self._analyze_sentences(text)
        
        # ë‹´í™” ë¶„ì„
        discourse_result = self._analyze_discourse(text)
        
        return {
            'morpheme': morpheme_result,
            'word': word_result,
            'phrase': phrase_result,
            'sentence': sentence_result,
            'discourse': discourse_result,
            'text': text
        }
    
    def _analyze_morphemes(self, text: str) -> Dict:
        """í˜•íƒœì†Œ ë¶„ì„ - í•œêµ­ì–´ íŠ¹í™”"""
        
        detected_morphemes = []
        total_intensity = 0.0
        cultural_weight = 0.0
        
        # í•œêµ­ì–´ í˜•íƒœì†Œ ê°ì • ë§¤í•‘
        for morpheme, emotion_data in self.korean_emotions['morphemes'].items():
            count = text.count(morpheme)
            if count > 0:
                detected_morphemes.append({
                    'morpheme': morpheme,
                    'emotion': emotion_data['emotion'],
                    'intensity': emotion_data['intensity'] * count,
                    'cultural_significance': emotion_data['cultural_weight'],
                    'count': count
                })
                total_intensity += emotion_data['intensity'] * count
                cultural_weight += emotion_data['cultural_weight']
        
        confidence = min(len(detected_morphemes) * 0.2 + cultural_weight * 0.3, 1.0)
        
        return {
            'detected_morphemes': detected_morphemes,
            'total_intensity': min(total_intensity, 1.0),
            'cultural_significance': cultural_weight / max(len(detected_morphemes), 1),
            'confidence': confidence,
            'micro_adjustment_power': min(len(detected_morphemes) * 0.3, 1.0)
        }
    
    def _analyze_words(self, text: str) -> Dict:
        """ë‹¨ì–´ ë¶„ì„"""
        
        detected_words = []
        valence_sum = 0.0
        arousal_sum = 0.0
        
        for word, emotion_data in self.korean_emotions['words'].items():
            if word in text:
                detected_words.append({
                    'word': word,
                    'valence': emotion_data['valence'],
                    'arousal': emotion_data['arousal'],
                    'complexity': emotion_data.get('complexity', 0.5)
                })
                valence_sum += emotion_data['valence']
                arousal_sum += emotion_data['arousal']
        
        word_count = max(len(detected_words), 1)
        
        return {
            'detected_words': detected_words,
            'average_valence': valence_sum / word_count,
            'average_arousal': arousal_sum / word_count,
            'word_diversity': len(detected_words),
            'confidence': min(len(detected_words) * 0.15, 1.0)
        }
    
    def _analyze_phrases(self, text: str) -> Dict:
        """êµ¬ë¬¸ ë¶„ì„ - ë°˜ì–´ë²•, ì™„ê³¡ í‘œí˜„ ë“±"""
        
        detected_patterns = []
        
        # ë°˜ì–´ë²• íŒ¨í„´
        sarcasm_patterns = [r'ì°¸.*ì˜.*í–ˆ', r'ì •ë§.*ëŒ€ë‹¨', r'ì™€.*ì¢‹']
        
        import re
        for pattern in sarcasm_patterns:
            if re.search(pattern, text):
                detected_patterns.append({
                    'type': 'sarcasm',
                    'confidence': 0.8,
                    'emotion_shift': -0.8  # ê°ì • ë°˜ì „
                })
        
        # ì™„ê³¡ í‘œí˜„
        polite_patterns = ['ì•„ë¬´ë˜ë„', 'ì¢€', 'ì¡°ê¸ˆ', 'ì•½ê°„']
        politeness_level = sum(text.count(marker) for marker in polite_patterns) * 0.3
        
        return {
            'detected_patterns': detected_patterns,
            'sarcasm_detected': any(p['type'] == 'sarcasm' for p in detected_patterns),
            'politeness_level': min(politeness_level, 1.0),
            'confidence': 0.7 if detected_patterns else 0.5
        }
    
    def _analyze_sentences(self, text: str) -> Dict:
        """ë¬¸ì¥ ë¶„ì„"""
        
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        
        emotional_variation = 0.0
        if len(sentences) > 1:
            sentence_lengths = [len(s) for s in sentences]
            emotional_variation = np.std(sentence_lengths) / np.mean(sentence_lengths)
        
        complexity_score = len(sentences) + text.count('í•˜ì§€ë§Œ') + text.count('ê·¸ëŸ°ë°')
        
        return {
            'sentence_count': len(sentences),
            'average_length': np.mean([len(s) for s in sentences]) if sentences else 0,
            'emotional_variation': emotional_variation,
            'complexity_score': min(complexity_score, 10),
            'confidence': min(len(sentences) * 0.2, 1.0)
        }
    
    def _analyze_discourse(self, text: str) -> Dict:
        """ë‹´í™” ë¶„ì„"""
        
        # ì „ì²´ì  í†¤ ê³„ì‚°
        positive_words = ['ì¢‹', 'ê¸°ì˜', 'í–‰ë³µ', 'ë§Œì¡±']
        negative_words = ['ìŠ¬í”„', 'í™”ë‚˜', 'ì‹«', 'ìš°ìš¸']
        
        positive_count = sum(text.count(word) for word in positive_words)
        negative_count = sum(text.count(word) for word in negative_words)
        
        overall_tone = (positive_count - negative_count) / max(len(text) / 10, 1)
        overall_tone = max(-1.0, min(1.0, overall_tone))
        
        # ì¼ê´€ì„± ì ìˆ˜
        words = text.split()
        unique_ratio = len(set(words)) / max(len(words), 1)
        coherence_score = min(unique_ratio * 1.5, 1.0)
        
        return {
            'overall_tone': overall_tone,
            'coherence_score': coherence_score,
            'text_length': len(text),
            'contextual_power': min(len(text) / 100, 1.0),
            'confidence': min(len(text) / 50, 1.0)
        }
    
    def _process_bidirectional_interactions(self, hierarchical_analysis: Dict) -> Dict:
        """ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© ì²˜ë¦¬ - í•µì‹¬ ì•Œê³ ë¦¬ì¦˜"""
        
        layers = ['morpheme', 'word', 'phrase', 'sentence', 'discourse']
        
        # ê° ê³„ì¸µì˜ ì£¼ìš” ê°’ ì¶”ì¶œ
        layer_values = {
            'morpheme': hierarchical_analysis['morpheme']['total_intensity'],
            'word': hierarchical_analysis['word']['average_valence'],
            'phrase': len(hierarchical_analysis['phrase']['detected_patterns']),
            'sentence': hierarchical_analysis['sentence']['emotional_variation'],
            'discourse': hierarchical_analysis['discourse']['overall_tone']
        }
        
        # Up-Down ì˜í–¥ ê³„ì‚° (ë‹´í™” â†’ í˜•íƒœì†Œ)
        discourse_tone = layer_values['discourse']
        up_down_effects = {}
        
        for layer in layers[:-1]:  # discourse ì œì™¸
            if discourse_tone < -0.3:  # ë¶€ì •ì  ë‹´í™” í†¤
                adjustment = abs(discourse_tone) * self.interaction_weights['up_down_strength']
                up_down_effects[layer] = -adjustment
            else:
                up_down_effects[layer] = 0.0
        
        # Down-Up ì˜í–¥ ê³„ì‚° (í˜•íƒœì†Œ â†’ ë‹´í™”)
        morpheme_power = hierarchical_analysis['morpheme']['micro_adjustment_power']
        down_up_effects = {}
        
        if morpheme_power > 0.7:  # ê°•í•œ í˜•íƒœì†Œ ì˜í–¥
            adjustment = morpheme_power * self.interaction_weights['down_up_strength']
            for layer in layers[1:]:  # morpheme ì œì™¸
                down_up_effects[layer] = adjustment * 0.3
        else:
            for layer in layers[1:]:
                down_up_effects[layer] = 0.0
        
        # ìƒí˜¸ì‘ìš© ê°•ë„ ê³„ì‚°
        up_down_strength = np.mean(list(up_down_effects.values()))
        down_up_strength = np.mean(list(down_up_effects.values()))
        
        # ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •
        self._adjust_dynamic_weights(hierarchical_analysis, up_down_strength, down_up_strength)
        
        return {
            'up_down_effects': up_down_effects,
            'down_up_effects': down_up_effects,
            'up_down_strength': up_down_strength,
            'down_up_strength': down_up_strength,
            'dominant_direction': 'up_down' if abs(up_down_strength) > abs(down_up_strength) else 'down_up',
            'interaction_balance': abs(up_down_strength - down_up_strength)
        }
    
    def _generate_emotion_vector(self, hierarchical_analysis: Dict, bidirectional_effects: Dict) -> EmotionVector:
        """28ì°¨ì› ê°ì • ë²¡í„° ìƒì„±"""
        
        # 0-7ì°¨ì›: ì§„í­ ì„±ë¶„ (ê°ì • ê°•ë„)
        amplitude = np.array([
            hierarchical_analysis['discourse']['overall_tone'],  # ì „ì²´ í†¤
            hierarchical_analysis['morpheme']['total_intensity'],  # í˜•íƒœì†Œ ê°•ë„
            hierarchical_analysis['word']['average_valence'],  # ë‹¨ì–´ ê°ì •ê°€
            hierarchical_analysis['phrase']['politeness_level'],  # ì •ì¤‘í•¨
            hierarchical_analysis['sentence']['emotional_variation'],  # ê°ì • ë³€í™”
            hierarchical_analysis['morpheme']['cultural_significance'],  # ë¬¸í™”ì  ì˜ë¯¸
            hierarchical_analysis['discourse']['contextual_power'],  # ë§¥ë½ë ¥
            bidirectional_effects['interaction_balance']  # ìƒí˜¸ì‘ìš© ê· í˜•
        ])
        
        # 8-15ì°¨ì›: ìœ„ìƒ ì„±ë¶„ (ê´€ê³„ì„±)
        phase = np.array([
            bidirectional_effects['up_down_strength'],  # í•˜í–¥ ì˜í–¥ë ¥
            bidirectional_effects['down_up_strength'],  # ìƒí–¥ ì˜í–¥ë ¥
            hierarchical_analysis['morpheme']['micro_adjustment_power'],  # ë¯¸ì„¸ ì¡°ì •ë ¥
            hierarchical_analysis['sentence']['complexity_score'] / 10,  # êµ¬ì¡° ë³µì¡ë„
            hierarchical_analysis['word']['word_diversity'] / 10,  # ì–´íœ˜ ë‹¤ì–‘ì„±
            len(hierarchical_analysis['phrase']['detected_patterns']) / 5,  # íŒ¨í„´ ë°€ë„
            hierarchical_analysis['discourse']['coherence_score'],  # ì¼ê´€ì„±
            np.random.normal(0.5, 0.1)  # ì°½ì˜ì  ë³€ë™ì„±
        ])
        
        # 16-21ì°¨ì›: ê°ì • ì„±ë¶„
        overall_tone = hierarchical_analysis['discourse']['overall_tone']
        emotion_components = np.array([
            max(0, overall_tone),  # ê¸ì •ì„±
            max(0, -overall_tone),  # ë¶€ì •ì„±
            1 - abs(overall_tone),  # ì¤‘ë¦½ì„±
            np.std([hierarchical_analysis[layer]['confidence'] for layer in ['morpheme', 'word', 'phrase', 'sentence', 'discourse']]),  # ë³µì¡ì„±
            hierarchical_analysis['morpheme']['cultural_significance'],  # ë¬¸í™”ì  ë‰˜ì•™ìŠ¤
            hierarchical_analysis['phrase']['politeness_level']  # ì‚¬íšŒì  ê´€ê³„ì„±
        ])
        
        # 22-27ì°¨ì›: ì¼ê´€ì„± ì§€ìˆ˜
        confidences = [hierarchical_analysis[layer]['confidence'] for layer in ['morpheme', 'word', 'phrase', 'sentence', 'discourse']]
        consistency = np.array([
            np.mean(confidences),  # ì „ì²´ ì¼ê´€ì„±
            1 - np.std(confidences),  # ê³„ì¸µê°„ ì¼ê´€ì„±
            hierarchical_analysis['discourse']['coherence_score'],  # ë‹´í™” ì¼ê´€ì„±
            self._calculate_temporal_consistency(hierarchical_analysis),  # ì‹œê°„ì  ì¼ê´€ì„±
            self._calculate_cultural_consistency(hierarchical_analysis),  # ë¬¸í™”ì  ì¼ê´€ì„±
            bidirectional_effects['interaction_balance']  # ìƒí˜¸ì‘ìš© ì¼ê´€ì„±
        ])
        
        return EmotionVector(
            amplitude=amplitude,
            phase=phase,
            emotion_components=emotion_components,
            consistency=consistency
        )
    
    def _convert_to_music(self, emotion_vector: EmotionVector) -> Dict:
        """ê°ì • ë²¡í„°ë¥¼ ìŒì•… í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
        
        # ì£¼ìš” ê°ì • íŠ¹ì„± ì¶”ì¶œ
        overall_tone = emotion_vector.amplitude[0]
        intensity = np.mean(emotion_vector.amplitude)
        complexity = emotion_vector.emotion_components[3]
        cultural_nuance = emotion_vector.emotion_components[4]
        
        # ìŒì•… ìŠ¤íƒ€ì¼ ê²°ì •
        if cultural_nuance > 0.7:
            base_style = 'korean_traditional'
        elif complexity > 0.7:
            base_style = 'complex_harmony'
        elif overall_tone > 0.5:
            base_style = 'bright_major'
        elif overall_tone < -0.5:
            base_style = 'melancholy_minor'
        else:
            base_style = 'neutral_modal'
        
        # í…œí”Œë¦¿ì—ì„œ ê¸°ë³¸ êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°
        template = self.music_templates.get(base_style, self.music_templates['neutral_modal'])
        
        # ê°ì • ë²¡í„°ì— ë”°ë¥¸ ì¡°ì •
        music_expression = template.copy()
        
        # í…œí¬ ì¡°ì • (ê°ì„±ë„ ê¸°ë°˜)
        arousal = np.mean(emotion_vector.amplitude[1:4])
        tempo_adjustment = (arousal - 0.5) * 40
        music_expression['tempo'] = max(60, min(180, int(template['tempo'] + tempo_adjustment)))
        
        # ê°•ì•½ ì¡°ì • (ê°•ë„ ê¸°ë°˜)
        if intensity > 0.8:
            music_expression['dynamics'] = 'fortissimo'
        elif intensity > 0.6:
            music_expression['dynamics'] = 'forte'
        elif intensity > 0.4:
            music_expression['dynamics'] = 'mezzo_forte'
        elif intensity > 0.2:
            music_expression['dynamics'] = 'mezzo_piano'
        else:
            music_expression['dynamics'] = 'piano'
        
        # ê°ì • ì•„í¬ ìƒì„± (8ë§ˆë””)
        emotional_arc = []
        for i in range(8):
            measure_intensity = emotion_vector.amplitude[i % 8]
            emotional_arc.append(float(measure_intensity))
        
        music_expression.update({
            'emotional_arc': emotional_arc,
            'complexity_level': float(complexity),
            'cultural_elements': self._extract_cultural_elements(cultural_nuance),
            'harmonic_progression': self._generate_harmonic_progression(emotion_vector),
            'expression_markings': self._generate_expression_markings(emotion_vector)
        })
        
        return music_expression
    
    def _perform_real_time_learning(self, hierarchical_analysis: Dict, emotion_vector: EmotionVector, 
                                   music_expression: Dict, user_feedback: Dict) -> Dict:
        """ì‹¤ì‹œê°„ í•™ìŠµ ìˆ˜í–‰"""
        
        # ê²½í—˜ ì €ì¥
        experience = {
            'timestamp': time.time(),
            'hierarchical_analysis': hierarchical_analysis,
            'emotion_vector': emotion_vector,
            'music_expression': music_expression,
            'user_feedback': user_feedback,
            'weights_used': self.dynamic_weights.copy()
        }
        self.memory.experiences.append(experience)
        
        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        accuracy = user_feedback.get('accuracy_rating', 5) / 10.0
        self.memory.performance_history.append(accuracy)
        
        # ê°€ì¤‘ì¹˜ ì¡°ì •
        if accuracy < 0.6:  # ì„±ëŠ¥ì´ ë‚®ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¡°ì •
            self._adjust_weights_from_feedback(hierarchical_analysis, user_feedback)
        
        # ì ì‘ë¥  ê³„ì‚°
        if len(self.memory.performance_history) >= 10:
            recent_scores = list(self.memory.performance_history)[-10:]
            adaptation_rate = np.std(recent_scores)
            self.performance_metrics['adaptation_rate'] = adaptation_rate
        
        return {
            'learning_executed': True,
            'accuracy_score': accuracy,
            'weights_adjusted': accuracy < 0.6,
            'experience_count': len(self.memory.experiences),
            'adaptation_rate': self.performance_metrics.get('adaptation_rate', 0.0)
        }
    
    def _adjust_dynamic_weights(self, hierarchical_analysis: Dict, up_down_strength: float, down_up_strength: float):
        """ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •"""
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì¡°ì •
        for layer in self.dynamic_weights:
            confidence = hierarchical_analysis[layer]['confidence']
            if confidence > 0.8:
                self.dynamic_weights[layer] *= 1.1  # ì‹ ë¢°ë„ ë†’ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€
            elif confidence < 0.4:
                self.dynamic_weights[layer] *= 0.9  # ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ ê°€ì¤‘ì¹˜ ê°ì†Œ
        
        # ìƒí˜¸ì‘ìš© ê°•ë„ ê¸°ë°˜ ì¡°ì •
        if abs(up_down_strength) > abs(down_up_strength):
            # í•˜í–¥ ì˜í–¥ì´ ê°•í•˜ë©´ ìƒìœ„ ê³„ì¸µ ê°€ì¤‘ì¹˜ ì¦ê°€
            self.dynamic_weights['discourse'] *= 1.05
            self.dynamic_weights['morpheme'] *= 0.95
        else:
            # ìƒí–¥ ì˜í–¥ì´ ê°•í•˜ë©´ í•˜ìœ„ ê³„ì¸µ ê°€ì¤‘ì¹˜ ì¦ê°€
            self.dynamic_weights['morpheme'] *= 1.05
            self.dynamic_weights['discourse'] *= 0.95
        
        # ì •ê·œí™”
        total_weight = sum(self.dynamic_weights.values())
        self.dynamic_weights = {k: v/total_weight for k, v in self.dynamic_weights.items()}
    
    def _adjust_weights_from_feedback(self, hierarchical_analysis: Dict, user_feedback: Dict):
        """ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •"""
        
        correct_emotion = user_feedback.get('correct_emotion', '')
        
        # ê°ì •ë³„ ê³„ì¸µ ì¤‘ìš”ë„ ì¡°ì •
        if 'ë³µí•©' in correct_emotion or 'ë¯¸ë¬˜' in correct_emotion:
            # ë³µí•©ê°ì •ì´ë©´ í˜•íƒœì†Œì™€ êµ¬ë¬¸ ì¤‘ìš”ë„ ì¦ê°€
            self.dynamic_weights['morpheme'] *= 1.1
            self.dynamic_weights['phrase'] *= 1.1
        elif 'ê°•í•œ' in correct_emotion or 'ëª…í™•' in correct_emotion:
            # ê°•í•œ ê°ì •ì´ë©´ ë‹¨ì–´ì™€ ë‹´í™” ì¤‘ìš”ë„ ì¦ê°€
            self.dynamic_weights['word'] *= 1.1
            self.dynamic_weights['discourse'] *= 1.1
        
        # ì •ê·œí™”
        total_weight = sum(self.dynamic_weights.values())
        self.dynamic_weights = {k: v/total_weight for k, v in self.dynamic_weights.items()}
    
    def _calculate_confidence(self, hierarchical_analysis: Dict, bidirectional_effects: Dict) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        
        # ê³„ì¸µë³„ ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        layer_confidences = [hierarchical_analysis[layer]['confidence'] for layer in ['morpheme', 'word', 'phrase', 'sentence', 'discourse']]
        weighted_confidence = sum(conf * weight for conf, weight in zip(layer_confidences, self.dynamic_weights.values()))
        
        # ìƒí˜¸ì‘ìš© ê· í˜•ë„ ë°˜ì˜
        interaction_confidence = 1.0 - bidirectional_effects['interaction_balance']
        
        # ì „ì²´ ì‹ ë¢°ë„
        overall_confidence = (weighted_confidence * 0.8 + interaction_confidence * 0.2)
        
        return min(overall_confidence, 1.0)
    
    def _update_performance_metrics(self, confidence_score: float, user_feedback: Optional[Dict]):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        
        self.performance_metrics['total_analyses'] += 1
        
        if user_feedback:
            accuracy = user_feedback.get('accuracy_rating', 5) / 10.0
            self.performance_metrics['accuracy_trend'].append(accuracy)
            
            # ìµœê·¼ 10ê°œ í‰ê· ìœ¼ë¡œ íŠ¸ë Œë“œ ê³„ì‚°
            if len(self.performance_metrics['accuracy_trend']) > 10:
                self.performance_metrics['accuracy_trend'] = self.performance_metrics['accuracy_trend'][-10:]
    
    def get_system_status(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        
        return {
            'performance_metrics': self.performance_metrics,
            'dynamic_weights': self.dynamic_weights,
            'interaction_weights': self.interaction_weights,
            'memory_usage': {
                'experiences': len(self.memory.experiences),
                'performance_history': len(self.memory.performance_history),
                'weights_history': len(self.memory.weights_history)
            },
            'learning_active': self.learning_active,
            'system_health': self._calculate_system_health()
        }
    
    def _calculate_system_health(self) -> float:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ê³„ì‚°"""
        
        if len(self.memory.performance_history) < 5:
            return 0.7  # ì´ˆê¸°ê°’
        
        recent_performance = list(self.memory.performance_history)[-10:]
        avg_performance = np.mean(recent_performance)
        performance_stability = 1.0 - np.std(recent_performance)
        
        return (avg_performance + performance_stability) / 2
    
    # í—¬í¼ ë©”ì„œë“œë“¤
    def _initialize_korean_emotions(self) -> Dict:
        """í•œêµ­ì–´ ê°ì • ì‚¬ì „ ì´ˆê¸°í™”"""
        
        return {
            'morphemes': {
                'ë„¤ìš”': {'emotion': 'soft_discovery', 'intensity': 0.6, 'cultural_weight': 0.9},
                'êµ°ìš”': {'emotion': 'recognition', 'intensity': 0.5, 'cultural_weight': 0.8},
                'ê±°ë“ ìš”': {'emotion': 'justification', 'intensity': 0.7, 'cultural_weight': 0.9},
                'ì–ì•„ìš”': {'emotion': 'shared_knowledge', 'intensity': 0.6, 'cultural_weight': 0.9},
                'ë”ë¼ê³ ìš”': {'emotion': 'recollection', 'intensity': 0.5, 'cultural_weight': 0.8}
            },
            'words': {
                'ì¢‹': {'valence': 0.8, 'arousal': 0.6, 'complexity': 0.2},
                'ê¸°ì˜': {'valence': 0.9, 'arousal': 0.8, 'complexity': 0.3},
                'ìŠ¬í”„': {'valence': -0.8, 'arousal': 0.3, 'complexity': 0.4},
                'í™”ë‚˜': {'valence': -0.7, 'arousal': 0.9, 'complexity': 0.3},
                'ê·¸ë¦½': {'valence': -0.3, 'arousal': 0.5, 'complexity': 0.9},
                'ì•„ë ¨': {'valence': -0.2, 'arousal': 0.3, 'complexity': 0.9}
            }
        }
    
    def _initialize_music_templates(self) -> Dict:
        """ìŒì•… í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        
        return {
            'korean_traditional': {
                'scale': 'pentatonic',
                'tempo': 80,
                'dynamics': 'mezzo_piano',
                'chords': ['Am', 'Dm', 'G', 'C', 'F'],
                'mood': 'contemplative'
            },
            'complex_harmony': {
                'scale': 'chromatic',
                'tempo': 100,
                'dynamics': 'mezzo_forte',
                'chords': ['Cmaj7', 'Am7', 'Dm7', 'G7', 'Em7'],
                'mood': 'sophisticated'
            },
            'bright_major': {
                'scale': 'major',
                'tempo': 120,
                'dynamics': 'forte',
                'chords': ['C', 'G', 'Am', 'F'],
                'mood': 'joyful'
            },
            'melancholy_minor': {
                'scale': 'minor',
                'tempo': 70,
                'dynamics': 'piano',
                'chords': ['Am', 'F', 'C', 'G'],
                'mood': 'melancholic'
            },
            'neutral_modal': {
                'scale': 'dorian',
                'tempo': 90,
                'dynamics': 'mezzo_piano',
                'chords': ['Dm', 'G', 'C', 'F'],
                'mood': 'balanced'
            }
        }
    
    def _calculate_temporal_consistency(self, hierarchical_analysis: Dict) -> float:
        """ì‹œê°„ì  ì¼ê´€ì„± ê³„ì‚°"""
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ í•„ìš”
        return 0.8
    
    def _calculate_cultural_consistency(self, hierarchical_analysis: Dict) -> float:
        """ë¬¸í™”ì  ì¼ê´€ì„± ê³„ì‚°"""
        morpheme_cultural = hierarchical_analysis['morpheme']['cultural_significance']
        phrase_politeness = hierarchical_analysis['phrase']['politeness_level']
        return (morpheme_cultural + phrase_politeness) / 2
    
    def _extract_cultural_elements(self, cultural_nuance: float) -> List[str]:
        """ë¬¸í™”ì  ìš”ì†Œ ì¶”ì¶œ"""
        elements = []
        if cultural_nuance > 0.7:
            elements.extend(['í•œêµ­ì  ì„ ìœ¨ë²•', 'ë¯¸ì„¸ìŒ êµ½í˜'])
        if cultural_nuance > 0.5:
            elements.append('í˜¸í¡ë²•ì  í”„ë ˆì´ì§•')
        return elements
    
    def _generate_harmonic_progression(self, emotion_vector: EmotionVector) -> List[str]:
        """í™”ì„± ì§„í–‰ ìƒì„±"""
        # ê°ì • ë²¡í„° ê¸°ë°˜ í™”ì„± ì§„í–‰ ìƒì„± (ë‹¨ìˆœí™”)
        base_chords = ['C', 'Am', 'F', 'G']
        if emotion_vector.emotion_components[1] > 0.5:  # ë¶€ì •ì 
            base_chords = ['Am', 'Dm', 'G', 'C']
        return base_chords
    
    def _generate_expression_markings(self, emotion_vector: EmotionVector) -> List[str]:
        """í‘œí˜„ ê¸°í˜¸ ìƒì„±"""
        markings = []
        if emotion_vector.emotion_components[4] > 0.7:  # ë¬¸í™”ì  ë‰˜ì•™ìŠ¤
            markings.append('í•œêµ­ì  ì •ì„œë¡œ ì—°ì£¼')
        if emotion_vector.emotion_components[3] > 0.7:  # ë³µì¡ì„±
            markings.append('ë³µì¡í•œ ê°ì •ì˜ ì¸µìœ„ë¥¼ í‘œí˜„')
        return markings

# =============================================================================
# 3. ì‚¬ìš© ì˜ˆì‹œ
# =============================================================================

def main_demo():
    """í†µí•© ì‹œìŠ¤í…œ ë°ëª¨"""
    
    print("ğŸ¼ í†µí•©ëœ ì–‘ë°©í–¥ ê°ì •-ìŒì•… ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = UnifiedBidirectionalSystem()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            'text': "ì°¸ ì˜í–ˆì–´ìš”. ì •ë§ ëŒ€ë‹¨í•˜ë„¤ìš”. ì•„ë¬´ë˜ë„ ì´ëŸ° ì‹ìœ¼ë¡œ í•˜ì‹œë©´ ë  ê²ƒ ê°™ì•„ìš”.",
            'feedback': {'accuracy_rating': 8, 'correct_emotion': 'ë³µí•©ê°ì •_ë°˜ì–´ë²•'}
        },
        {
            'text': "ì˜¤ëŠ˜ ì •ë§ ì¢‹ì€ í•˜ë£¨ì˜€ì–´ìš”. ê¸°ë¶„ì´ ë„ˆë¬´ ì¢‹ë„¤ìš”!",
            'feedback': {'accuracy_rating': 9, 'correct_emotion': 'ìˆœìˆ˜í•œ_ê¸°ì¨'}
        },
        {
            'text': "ê·¸ë•Œê°€ ì°¸ ê·¸ë¦¬ì›Œìš”... ë‹¤ì‹œëŠ” ëŒì•„ê°ˆ ìˆ˜ ì—†ì„ í…ë°.",
            'feedback': {'accuracy_rating': 7, 'correct_emotion': 'ê·¸ë¦¬ì›€_ë³µí•©ê°ì •'}
        }
    ]
    
    print("ë¶„ì„ ì‹œì‘...\n")
    
    for i, case in enumerate(test_cases, 1):
        print(f"[ì¼€ì´ìŠ¤ {i}] {case['text']}")
        print("-" * 30)
        
        # ì²« ë²ˆì§¸ëŠ” í”¼ë“œë°± ì—†ì´, ë‚˜ë¨¸ì§€ëŠ” í”¼ë“œë°±ê³¼ í•¨ê»˜
        feedback = case['feedback'] if i > 1 else None
        
        result = system.analyze_emotion_to_music(case['text'], feedback)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ¯ ì‹ ë¢°ë„: {result.confidence_score:.3f}")
        print(f"â±ï¸  ì²˜ë¦¬ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
        
        # ê°ì • ë²¡í„° ì£¼ìš” ì •ë³´
        emotion = result.emotion_vector
        print(f"ğŸ“Š ì „ì²´í†¤: {emotion.amplitude[0]:.3f}")
        print(f"ğŸ”„ ìƒí˜¸ì‘ìš©: ìƒí–¥={emotion.phase[1]:.3f}, í•˜í–¥={emotion.phase[0]:.3f}")
        print(f"ğŸ¨ ë¬¸í™”ì ìš”ì†Œ: {emotion.emotion_components[4]:.3f}")
        
        # ìŒì•… í‘œí˜„
        music = result.music_expression
        print(f"ğŸµ ìŒì•…: {music['mood']} / {music['tempo']}BPM / {music['dynamics']}")
        print(f"ğŸ¶ í™”ì„±: {' - '.join(music['harmonic_progression'])}")
        
        if result.adaptation_metadata:
            print(f"ğŸ§  í•™ìŠµ: ì •í™•ë„={result.adaptation_metadata['accuracy_score']:.3f}")
        
        print()
    
    # ìµœì¢… ì‹œìŠ¤í…œ ìƒíƒœ
    print("=" * 50)
    status = system.get_system_status()
    print(f"ğŸ“ˆ ì´ ë¶„ì„: {status['performance_metrics']['total_analyses']}íšŒ")
    print(f"ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„: {status['system_health']:.3f}")
    print(f"ğŸ›ï¸  í˜„ì¬ ê°€ì¤‘ì¹˜: {[f'{k}:{v:.2f}' for k, v in status['dynamic_weights'].items()]}")

if __name__ == "__main__":
    main_demo()