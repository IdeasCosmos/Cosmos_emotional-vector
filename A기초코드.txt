A. Í≤ΩÎüâ Îç∞Î™® API (Ï∂îÏ≤ú ÏãúÏûë)
B. Ï†ÑÏ≤¥ COSMOS ÌÜµÌï© (Í≥†ÎÇúÏù¥ÎèÑ)
C. Î≤§ÏπòÎßàÌÅ¨¬∑Ï†ïÌôïÎèÑ Í≤ÄÏ¶ù Ïä§ÏúÑÌä∏ Ïö∞ÏÑ†

ÌïµÏã¨ Ìè¨Ìï® ÏÇ¨Ìï≠:
- EEG Analyzer (Goertzel/Kalman/SNR)
- OptimizedEmotionEngine
- /analyze, /health ÏóîÎìúÌè¨Ïù∏Ìä∏
- YAML Îß§Ìïë Î°úÎçî
- Îã®ÏúÑ ÌÖåÏä§Ìä∏

Ï†úÏô∏:
- BERT Îì± Î¨¥Í±∞Ïö¥ Î™®Îç∏
- Î≥µÏû°Ìïú ÏãúÍ∞ÅÌôî
- Ï†ÑÏ≤¥ COSMOS ÏïÑÌÇ§ÌÖçÏ≤ò

Î™©ÌëúÎäî Îπ†Î•¥Í≤å Ïã§ÌñâÌïòÍ≥† Í≤ÄÏ¶ùÌï† Ïàò ÏûàÎäî ÏãúÏä§ÌÖú ÌôïÏù∏.

ÏòµÏÖò A: Í≤ΩÎüâ Îç∞Î™® API - Ï¶âÏãú Ïã§Ìñâ Í∞ÄÎä•

*ÏòµÏÖò A (Í≤ΩÎüâ Îç∞Î™® API)* ÌïµÏã¨ Í∏∞Îä•Îßå Ìè¨Ìï®

"""
Lightweight Demo API for SHEMS
Immediate deployment with core functionality only
No heavy dependencies, runs on basic hardware
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Tuple
import numpy as np
import yaml
from pathlib import Path
import time
import asyncio
from dataclasses import dataclass
from enum import Enum
import logging
import json
from scipy import signal
from scipy.signal import butter, filtfilt
import hashlib

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    """Minimal configuration for demo"""
    # EEG Settings
    SAMPLING_RATE = 256  # Hz (standard for most EEG devices)
    EEG_CHANNELS = 8     # Typical consumer EEG channel count
    
    # Frequency bands (Hz)
    BANDS = {
        'delta': (0.5, 4),
        'theta': (4, 8),
        'alpha': (8, 13),
        'beta': (13, 30),
        'gamma': (30, 50)
    }
    
    # Performance
    CACHE_SIZE = 100
    MAX_TEXT_LENGTH = 1000
    
    # API
    VERSION = "1.0-demo"
    PORT = 8000

config = Config()

# ============================================================================
# EEG ANALYZER with Goertzel/Kalman/SNR
# ============================================================================

class EEGAnalyzer:
    """Optimized EEG analysis with Goertzel algorithm and Kalman filtering"""
    
    def __init__(self, sampling_rate: int = 256):
        self.sampling_rate = sampling_rate
        self.kalman_state = None
        self.kalman_covariance = np.eye(5) * 0.1  # For 5 frequency bands
        
    def goertzel_algorithm(self, samples: np.ndarray, target_freq: float) -> float:
        """
        Goertzel algorithm for efficient single frequency detection
        Much faster than FFT for specific frequencies
        """
        N = len(samples)
        k = int(0.5 + N * target_freq / self.sampling_rate)
        omega = 2 * np.pi * k / N
        
        # Goertzel coefficients
        coeff = 2 * np.cos(omega)
        
        # Filter implementation
        s_prev = 0
        s_prev2 = 0
        
        for sample in samples:
            s = sample + coeff * s_prev - s_prev2
            s_prev2 = s_prev
            s_prev = s
        
        # Calculate power
        power = s_prev2 * s_prev2 + s_prev * s_prev - coeff * s_prev * s_prev2
        return np.sqrt(power) / N
    
    def extract_band_powers(self, eeg_signal: np.ndarray) -> Dict[str, float]:
        """Extract power in each frequency band using Goertzel"""
        band_powers = {}
        
        for band_name, (low_freq, high_freq) in config.BANDS.items():
            # Use Goertzel for center frequency of each band
            center_freq = (low_freq + high_freq) / 2
            power = self.goertzel_algorithm(eeg_signal, center_freq)
            
            # Normalize to z-score
            band_powers[band_name] = (power - 0.5) * 2  # Simple normalization
        
        return band_powers
    
    def kalman_filter(self, measurement: np.ndarray) -> np.ndarray:
        """Kalman filter for noise reduction"""
        # Initialize state if needed
        if self.kalman_state is None:
            self.kalman_state = measurement
            return measurement
        
        # Prediction step
        predicted_state = self.kalman_state
        predicted_covariance = self.kalman_covariance + np.eye(5) * 0.01
        
        # Update step
        innovation = measurement - predicted_state
        innovation_covariance = predicted_covariance + np.eye(5) * 0.1
        kalman_gain = predicted_covariance @ np.linalg.inv(innovation_covariance)
        
        # Update state and covariance
        self.kalman_state = predicted_state + kalman_gain @ innovation
        self.kalman_covariance = (np.eye(5) - kalman_gain) @ predicted_covariance
        
        return self.kalman_state
    
    def calculate_snr(self, signal: np.ndarray) -> float:
        """Calculate Signal-to-Noise Ratio"""
        # Simple SNR estimation using high-frequency content as noise
        noise_band = butter(4, [40, 50], btype='band', fs=self.sampling_rate)
        noise = filtfilt(noise_band[0], noise_band[1], signal)
        
        signal_power = np.mean(signal ** 2)
        noise_power = np.mean(noise ** 2)
        
        if noise_power > 0:
            snr = 10 * np.log10(signal_power / noise_power)
        else:
            snr = 40.0  # Good SNR
        
        return snr
    
    def process_eeg(self, raw_eeg: np.ndarray) -> Dict:
        """Complete EEG processing pipeline"""
        # Check SNR
        snr = self.calculate_snr(raw_eeg)
        
        if snr < 10:
            logger.warning(f"Low SNR detected: {snr:.2f} dB")
        
        # Extract band powers
        band_powers = self.extract_band_powers(raw_eeg)
        
        # Apply Kalman filtering
        band_array = np.array(list(band_powers.values()))
        filtered_bands = self.kalman_filter(band_array)
        
        # Update band powers with filtered values
        for i, band_name in enumerate(config.BANDS.keys()):
            band_powers[band_name] = float(filtered_bands[i])
        
        return {
            "band_powers": band_powers,
            "snr": snr,
            "quality": "good" if snr > 20 else "fair" if snr > 10 else "poor"
        }

# ============================================================================
# OPTIMIZED EMOTION ENGINE
# ============================================================================

class OptimizedEmotionEngine:
    """Lightweight emotion processing engine"""
    
    def __init__(self):
        self.yaml_mappings = self._load_yaml_mappings()
        self.cache = {}
        
    def _load_yaml_mappings(self) -> Dict:
        """Load YAML mappings (simplified for demo)"""
        # Embedded minimal mappings for demo
        return {
            'eeg_emotion_profiles': {
                'joy': {'delta': -0.10, 'theta': -0.05, 'alpha': 0.35, 'beta': 0.25, 'gamma': 0.15},
                'sadness': {'delta': 0.05, 'theta': 0.20, 'alpha': -0.25, 'beta': 0.10, 'gamma': 0.05},
                'anger': {'delta': 0.10, 'theta': 0.15, 'alpha': -0.30, 'beta': 0.40, 'gamma': 0.25},
                'fear': {'delta': 0.05, 'theta': 0.25, 'alpha': -0.35, 'beta': 0.30, 'gamma': 0.40},
                'disgust': {'delta': 0.10, 'theta': 0.20, 'alpha': -0.20, 'beta': 0.25, 'gamma': 0.10},
                'surprise': {'delta': -0.05, 'theta': 0.05, 'alpha': 0.10, 'beta': 0.30, 'gamma': 0.35},
                'neutral': {'delta': 0.00, 'theta': 0.00, 'alpha': 0.00, 'beta': 0.00, 'gamma': 0.00}
            },
            'korean_endings': {
                '-ÎÑ§Ïöî': [0.25, 0.05, 0.00, 0.30, 0.00, 0.40, -0.05],
                '-Íµ∞Ïöî': [0.10, 0.05, 0.00, 0.15, 0.00, 0.30, -0.05],
                '-Í±∞Îì†Ïöî': [0.00, 0.00, 0.35, 0.05, 0.00, 0.05, -0.10]
            }
        }
    
    def map_eeg_to_emotion(self, band_powers: Dict[str, float]) -> np.ndarray:
        """Map EEG band powers to emotion vector"""
        emotion_scores = {}
        
        # Compare with each emotion profile
        for emotion, profile in self.yaml_mappings['eeg_emotion_profiles'].items():
            score = 0
            for band, expected_value in profile.items():
                if band in band_powers:
                    # Calculate similarity (inverse of distance)
                    diff = abs(band_powers[band] - expected_value)
                    score += np.exp(-diff * 2)  # Exponential decay
            
            emotion_scores[emotion] = score / len(profile)
        
        # Convert to 7D emotion vector
        emotion_vector = np.array([
            emotion_scores.get('joy', 0),
            emotion_scores.get('sadness', 0),
            emotion_scores.get('anger', 0),
            emotion_scores.get('fear', 0),
            emotion_scores.get('disgust', 0),
            emotion_scores.get('surprise', 0),
            emotion_scores.get('neutral', 0)
        ])
        
        # Normalize
        if emotion_vector.sum() > 0:
            emotion_vector = emotion_vector / emotion_vector.sum()
        
        return emotion_vector
    
    def process_text(self, text: str) -> np.ndarray:
        """Simple text emotion analysis"""
        # Cache check
        text_hash = hashlib.md5(text.encode()).hexdigest()
        if text_hash in self.cache:
            return self.cache[text_hash]
        
        emotion_vector = np.zeros(7)
        
        # Check for Korean endings
        for ending, emotion_values in self.yaml_mappings['korean_endings'].items():
            if ending in text:
                emotion_vector += np.array(emotion_values)
        
        # Simple keyword matching (for demo)
        emotion_keywords = {
            0: ['Í∏∞ÏÅ®', 'ÌñâÎ≥µ', 'Ï¢ãÏïÑ', 'ÏÇ¨Îûë'],  # joy
            1: ['Ïä¨Ìîî', 'Ïö∞Ïö∏', 'ÎààÎ¨º', 'ÏïÑÌîÑ'],   # sadness
            2: ['ÌôîÎÇò', 'Î∂ÑÎÖ∏', 'ÏßúÏ¶ù', 'Ïó¥Î∞õ'],   # anger
            3: ['Î¨¥ÏÑú', 'ÎëêÎ†§', 'Í≥µÌè¨', 'Í≤ÅÎÇò'],   # fear
            4: ['Ïó≠Í≤®', 'ÎçîÎü¨', 'ÌòêÏò§', 'Ïã´Ïñ¥'],   # disgust
            5: ['ÎÜÄÎùº', 'ÍπúÏßù', 'Ìóâ', 'Ïñ¥Î®∏'],    # surprise
            6: ['Í∑∏ÎÉ•', 'Î≥¥ÌÜµ', 'ÌèâÎ≤î', 'Ï§ëÎ¶Ω']    # neutral
        }
        
        for idx, keywords in emotion_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    emotion_vector[idx] += 0.3
        
        # Normalize
        if emotion_vector.sum() > 0:
            emotion_vector = emotion_vector / emotion_vector.sum()
        else:
            emotion_vector[6] = 1.0  # Default to neutral
        
        # Cache result
        self.cache[text_hash] = emotion_vector
        
        return emotion_vector
    
    def emotion_to_music(self, emotion_vector: np.ndarray) -> Dict:
        """Convert emotion to music parameters"""
        # Valence and arousal from emotion vector
        valence = emotion_vector[0] - emotion_vector[1]  # joy - sadness
        arousal = (emotion_vector[2] + emotion_vector[3] + emotion_vector[5]) / 3
        
        # Generate music parameters
        music = {
            "tempo_bpm": int(60 + arousal * 60),  # 60-120 BPM
            "key": "C" if valence > 0 else "A",
            "mode": "major" if valence > 0 else "minor",
            "dynamics": self._get_dynamics(arousal),
            "chord_progression": self._get_progression(valence, arousal),
            "complexity": float(np.std(emotion_vector))
        }
        
        return music
    
    def _get_dynamics(self, arousal: float) -> str:
        """Map arousal to musical dynamics"""
        if arousal < 0.2:
            return "pp"
        elif arousal < 0.4:
            return "p"
        elif arousal < 0.6:
            return "mf"
        elif arousal < 0.8:
            return "f"
        else:
            return "ff"
    
    def _get_progression(self, valence: float, arousal: float) -> List[str]:
        """Select chord progression based on emotion"""
        if valence > 0 and arousal > 0.5:
            return ["I", "V", "vi", "IV"]  # Uplifting
        elif valence > 0:
            return ["I", "IV", "V", "I"]   # Classical happy
        elif valence < 0 and arousal > 0.5:
            return ["i", "iv", "VII", "III"]  # Dramatic minor
        else:
            return ["i", "iv", "v", "i"]   # Sad/contemplative

# ============================================================================
# API MODELS
# ============================================================================

class AnalyzeRequest(BaseModel):
    """Request model for /analyze endpoint"""
    text: Optional[str] = Field(None, max_length=config.MAX_TEXT_LENGTH)
    eeg_data: Optional[List[float]] = Field(None, description="Raw EEG samples")
    eeg_bands: Optional[Dict[str, float]] = Field(None, description="Pre-computed band powers")
    sampling_rate: Optional[int] = Field(config.SAMPLING_RATE, description="EEG sampling rate in Hz")

class AnalyzeResponse(BaseModel):
    """Response model for /analyze endpoint"""
    emotion_vector: List[float]
    confidence: float
    music_parameters: Dict
    processing_time_ms: float
    eeg_quality: Optional[str] = None
    snr_db: Optional[float] = None

class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    version: str
    uptime_seconds: float

# ============================================================================
# FAST API APPLICATION
# ============================================================================

app = FastAPI(
    title="SHEMS Lightweight Demo API",
    description="Emotion-Music Analysis with EEG Support",
    version=config.VERSION
)

# Initialize components
eeg_analyzer = EEGAnalyzer(sampling_rate=config.SAMPLING_RATE)
emotion_engine = OptimizedEmotionEngine()
app_start_time = time.time()

@app.get("/", response_model=Dict)
async def root():
    """API information"""
    return {
        "name": "SHEMS Demo API",
        "version": config.VERSION,
        "endpoints": ["/analyze", "/health", "/docs"],
        "features": ["EEG Analysis", "Text Emotion", "Music Mapping"]
    }

@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze(request: AnalyzeRequest):
    """Main analysis endpoint"""
    start_time = time.time()
    
    emotion_vectors = []
    eeg_quality = None
    snr_db = None
    
    try:
        # Process EEG if provided
        if request.eeg_data:
            # Convert to numpy array
            eeg_signal = np.array(request.eeg_data)
            
            # Process EEG
            eeg_result = eeg_analyzer.process_eeg(eeg_signal)
            
            # Map to emotion
            eeg_emotion = emotion_engine.map_eeg_to_emotion(eeg_result["band_powers"])
            emotion_vectors.append(eeg_emotion)
            
            eeg_quality = eeg_result["quality"]
            snr_db = eeg_result["snr"]
            
        elif request.eeg_bands:
            # Use pre-computed band powers
            eeg_emotion = emotion_engine.map_eeg_to_emotion(request.eeg_bands)
            emotion_vectors.append(eeg_emotion)
        
        # Process text if provided
        if request.text:
            text_emotion = emotion_engine.process_text(request.text)
            emotion_vectors.append(text_emotion)
        
        # Combine emotions if multiple sources
        if len(emotion_vectors) > 1:
            final_emotion = np.mean(emotion_vectors, axis=0)
        elif len(emotion_vectors) == 1:
            final_emotion = emotion_vectors[0]
        else:
            # No input provided
            raise HTTPException(status_code=400, detail="No input data provided")
        
        # Generate music parameters
        music_params = emotion_engine.emotion_to_music(final_emotion)
        
        # Calculate confidence
        confidence = 1.0 - np.std(final_emotion)  # Higher std = lower confidence
        
        processing_time = (time.time() - start_time) * 1000
        
        return AnalyzeResponse(
            emotion_vector=final_emotion.tolist(),
            confidence=float(confidence),
            music_parameters=music_params,
            processing_time_ms=processing_time,
            eeg_quality=eeg_quality,
            snr_db=snr_db
        )
        
    except Exception as e:
        logger.error(f"Analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health", response_model=HealthResponse)
async def health():
    """Health check endpoint"""
    uptime = time.time() - app_start_time
    
    return HealthResponse(
        status="healthy",
        version=config.VERSION,
        uptime_seconds=uptime
    )

# ============================================================================
# UNIT TESTS
# ============================================================================

import unittest

class TestEEGAnalyzer(unittest.TestCase):
    """Test EEG analysis functions"""
    
    def setUp(self):
        self.analyzer = EEGAnalyzer()
    
    def test_goertzel_algorithm(self):
        """Test Goertzel frequency detection"""
        # Generate test signal with known frequency
        t = np.linspace(0, 1, 256)
        freq = 10  # 10 Hz (alpha band)
        signal = np.sin(2 * np.pi * freq * t)
        
        # Detect frequency
        power = self.analyzer.goertzel_algorithm(signal, freq)
        
        # Should detect strong power at target frequency
        self.assertGreater(power, 0.3)
    
    def test_band_power_extraction(self):
        """Test frequency band extraction"""
        # Generate mixed frequency signal
        t = np.linspace(0, 1, 256)
        signal = (np.sin(2 * np.pi * 3 * t) +  # Delta
                 np.sin(2 * np.pi * 10 * t) +  # Alpha
                 np.sin(2 * np.pi * 20 * t))   # Beta
        
        band_powers = self.analyzer.extract_band_powers(signal)
        
        # Check all bands are present
        self.assertEqual(len(band_powers), 5)
        for band in ['delta', 'theta', 'alpha', 'beta', 'gamma']:
            self.assertIn(band, band_powers)
    
    def test_snr_calculation(self):
        """Test SNR calculation"""
        # Clean signal
        clean_signal = np.sin(2 * np.pi * 10 * np.linspace(0, 1, 256))
        snr_clean = self.analyzer.calculate_snr(clean_signal)
        
        # Noisy signal
        noisy_signal = clean_signal + np.random.randn(256) * 0.5
        snr_noisy = self.analyzer.calculate_snr(noisy_signal)
        
        # Clean should have better SNR
        self.assertGreater(snr_clean, snr_noisy)

class TestEmotionEngine(unittest.TestCase):
    """Test emotion processing"""
    
    def setUp(self):
        self.engine = OptimizedEmotionEngine()
    
    def test_eeg_to_emotion_mapping(self):
        """Test EEG band to emotion conversion"""
        # Test with joy-like EEG pattern
        band_powers = {
            'delta': -0.10,
            'theta': -0.05,
            'alpha': 0.35,
            'beta': 0.25,
            'gamma': 0.15
        }
        
        emotion = self.engine.map_eeg_to_emotion(band_powers)
        
        # Should have 7 dimensions
        self.assertEqual(len(emotion), 7)
        # Should sum to approximately 1 (normalized)
        self.assertAlmostEqual(emotion.sum(), 1.0, places=5)
        # Joy should be highest
        self.assertEqual(np.argmax(emotion), 0)
    
    def test_text_processing(self):
        """Test text emotion analysis"""
        # Test with happy text
        happy_text = "Ïò§Îäò Ï†ïÎßê Í∏∞ÏÅòÍ≥† ÌñâÎ≥µÌï¥Ïöî"
        emotion = self.engine.process_text(happy_text)
        
        # Joy should be dominant
        self.assertGreater(emotion[0], emotion[1])  # joy > sadness
        
        # Test with Korean ending
        surprise_text = "Ï†ïÎßê ÎÜÄÎûçÎÑ§Ïöî"
        emotion = self.engine.process_text(surprise_text)
        
        # Should detect surprise component
        self.assertGreater(emotion[5], 0)  # surprise > 0
    
    def test_music_generation(self):
        """Test music parameter generation"""
        # Happy emotion
        happy_emotion = np.array([0.6, 0.1, 0.1, 0.0, 0.0, 0.1, 0.1])
        music = self.engine.emotion_to_music(happy_emotion)
        
        self.assertEqual(music["mode"], "major")
        self.assertGreater(music["tempo_bpm"], 60)
        self.assertIn("chord_progression", music)

def run_tests():
    """Run all unit tests"""
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    suite.addTests(loader.loadTestsFromTestCase(TestEEGAnalyzer))
    suite.addTests(loader.loadTestsFromTestCase(TestEmotionEngine))
    
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    return result.wasSuccessful()

# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        # Run tests
        print("Running unit tests...")
        success = run_tests()
        sys.exit(0 if success else 1)
    else:
        # Run API server
        import uvicorn
        print(f"Starting SHEMS Demo API on port {config.PORT}...")
        print(f"Documentation available at: http://localhost:{config.PORT}/docs")
        uvicorn.run(app, host="0.0.0.0", port=config.PORT)

# requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
numpy==1.24.3
scipy==1.11.1
pyyaml==6.0.1
pydantic==2.5.0

---
# Dockerfile.demo
FROM python:3.10-slim

WORKDIR /app

# Install only essential dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY lightweight_demo_api.py .

# Health check
HEALTHCHECK --interval=30s --timeout=10s \
  CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["python", "lightweight_demo_api.py"]

---
# docker-compose.demo.yml
version: '3.8'

services:
  shems-demo:
    build:
      context: .
      dockerfile: Dockerfile.demo
    container_name: shems-demo-api
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

---
# test_client.py
"""
Quick test client for SHEMS Demo API
"""

import requests
import numpy as np
import json
import time

API_URL = "http://localhost:8000"

def test_text_analysis():
    """Test text emotion analysis"""
    print("\n=== Testing Text Analysis ===")
    
    payload = {
        "text": "Ïò§Îäò Ï†ïÎßê Í∏∞ÏÅòÎÑ§Ïöî! ÌñâÎ≥µÌïú ÌïòÎ£®ÏòÄÏñ¥Ïöî."
    }
    
    response = requests.post(f"{API_URL}/analyze", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Emotion Vector: {result['emotion_vector']}")
    print(f"Music: {result['music_parameters']}")
    print(f"Processing Time: {result['processing_time_ms']:.2f}ms")

def test_eeg_analysis():
    """Test EEG analysis with synthetic data"""
    print("\n=== Testing EEG Analysis ===")
    
    # Generate synthetic EEG (alpha wave dominant)
    t = np.linspace(0, 2, 512)  # 2 seconds at 256 Hz
    alpha_wave = np.sin(2 * np.pi * 10 * t)  # 10 Hz alpha
    noise = np.random.randn(512) * 0.1
    eeg_signal = (alpha_wave + noise).tolist()
    
    payload = {
        "eeg_data": eeg_signal,
        "sampling_rate": 256
    }
    
    response = requests.post(f"{API_URL}/analyze", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Emotion Vector: {result['emotion_vector']}")
    print(f"EEG Quality: {result.get('eeg_quality', 'N/A')}")
    print(f"SNR: {result.get('snr_db', 0):.2f} dB")
    print(f"Processing Time: {result['processing_time_ms']:.2f}ms")

def test_band_powers():
    """Test with pre-computed EEG band powers"""
    print("\n=== Testing Band Powers ===")
    
    # Simulate fear pattern
    payload = {
        "eeg_bands": {
            "delta": 0.05,
            "theta": 0.25,
            "alpha": -0.35,
            "beta": 0.30,
            "gamma": 0.40
        }
    }
    
    response = requests.post(f"{API_URL}/analyze", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Emotion Vector: {result['emotion_vector']}")
    print(f"Dominant Emotion: {['joy','sadness','anger','fear','disgust','surprise','neutral'][np.argmax(result['emotion_vector'])]}")
    print(f"Music Mode: {result['music_parameters']['mode']}")
    print(f"Tempo: {result['music_parameters']['tempo_bpm']} BPM")

def test_combined():
    """Test combined text and EEG analysis"""
    print("\n=== Testing Combined Analysis ===")
    
    payload = {
        "text": "Ï°∞Í∏à Î∂àÏïàÌïòÏßÄÎßå Í¥úÏ∞ÆÏïÑÏöî",
        "eeg_bands": {
            "delta": 0.10,
            "theta": 0.20,
            "alpha": -0.20,
            "beta": 0.25,
            "gamma": 0.15
        }
    }
    
    response = requests.post(f"{API_URL}/analyze", json=payload)
    result = response.json()
    
    print(f"Status: {response.status_code}")
    print(f"Emotion Vector: {result['emotion_vector']}")
    print(f"Confidence: {result['confidence']:.2%}")
    print(f"Chord Progression: {result['music_parameters']['chord_progression']}")

def benchmark():
    """Simple performance benchmark"""
    print("\n=== Performance Benchmark ===")
    
    # Prepare test data
    test_cases = []
    for i in range(100):
        test_cases.append({
            "text": f"ÌÖåÏä§Ìä∏ Î¨∏Ïû• {i}Î≤àÏûÖÎãàÎã§.",
            "eeg_bands": {
                "delta": np.random.randn() * 0.1,
                "theta": np.random.randn() * 0.1,
                "alpha": np.random.randn() * 0.1,
                "beta": np.random.randn() * 0.1,
                "gamma": np.random.randn() * 0.1
            }
        })
    
    # Run benchmark
    latencies = []
    errors = 0
    
    start_time = time.time()
    for case in test_cases:
        try:
            req_start = time.time()
            response = requests.post(f"{API_URL}/analyze", json=case)
            latency = (time.time() - req_start) * 1000
            
            if response.status_code == 200:
                latencies.append(latency)
            else:
                errors += 1
        except:
            errors += 1
    
    total_time = time.time() - start_time
    
    # Calculate statistics
    if latencies:
        print(f"Total Requests: {len(test_cases)}")
        print(f"Successful: {len(latencies)}")
        print(f"Errors: {errors}")
        print(f"Total Time: {total_time:.2f}s")
        print(f"Throughput: {len(latencies)/total_time:.2f} req/s")
        print(f"Average Latency: {np.mean(latencies):.2f}ms")
        print(f"P50 Latency: {np.percentile(latencies, 50):.2f}ms")
        print(f"P95 Latency: {np.percentile(latencies, 95):.2f}ms")
        print(f"P99 Latency: {np.percentile(latencies, 99):.2f}ms")

def main():
    """Run all tests"""
    print("SHEMS Demo API Test Client")
    print("="*50)
    
    # Check if API is running
    try:
        response = requests.get(f"{API_URL}/health")
        if response.status_code != 200:
            print("‚ùå API is not responding. Please start the server first.")
            return
        print("‚úÖ API is running")
    except:
        print("‚ùå Cannot connect to API. Please start the server first.")
        print("   Run: python lightweight_demo_api.py")
        return
    
    # Run tests
    test_text_analysis()
    test_eeg_analysis()
    test_band_powers()
    test_combined()
    benchmark()
    
    print("\n" + "="*50)
    print("All tests completed!")

if __name__ == "__main__":
    main()

---
# README.md
# SHEMS Lightweight Demo API

## üöÄ Quick Start (5 minutes)

### Option 1: Direct Python
```bash
# Install dependencies
pip install -r requirements.txt

# Run API server
python lightweight_demo_api.py

# API will be available at http://localhost:8000
# Documentation at http://localhost:8000/docs
```

### Option 2: Docker
```bash
# Build and run
docker-compose -f docker-compose.demo.yml up

# Or manually
docker build -f Dockerfile.demo -t shems-demo .
docker run -p 8000:8000 shems-demo
```

### Option 3: Quick Test
```bash
# Terminal 1 - Start server
python lightweight_demo_api.py

# Terminal 2 - Run tests
python lightweight_demo_api.py test

# Terminal 3 - Test client
pip install requests
python test_client.py
```

## üìä API Endpoints

### POST /analyze
Analyze emotion from text and/or EEG data.

**Request:**
```json
{
  "text": "Ïò§Îäò Í∏∞Î∂ÑÏù¥ Ï¢ãÏïÑÏöî",
  "eeg_data": [/* raw EEG samples */],
  "eeg_bands": {
    "delta": 0.1,
    "theta": 0.2,
    "alpha": 0.3,
    "beta": 0.2,
    "gamma": 0.1
  }
}
```

**Response:**
```json
{
  "emotion_vector": [0.4, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],
  "confidence": 0.85,
  "music_parameters": {
    "tempo_bpm": 120,
    "key": "C",
    "mode": "major",
    "dynamics": "mf",
    "chord_progression": ["I", "V", "vi", "IV"]
  },
  "processing_time_ms": 23.5,
  "eeg_quality": "good",
  "snr_db": 25.3
}
```

### GET /health
Health check endpoint.

## üß™ Testing

### Unit Tests
```bash
python lightweight_demo_api.py test
```

### Performance Test
```bash
python test_client.py
```

Expected performance:
- Latency: < 50ms (P95)
- Throughput: > 50 req/s
- Memory: < 200MB

## üìà EEG Input Formats

### Option 1: Raw EEG Signal
- Sampling rate: 256 Hz (configurable)
- Format: Array of float values
- Length: Any (typically 1-10 seconds)

### Option 2: Pre-computed Band Powers
- 5 bands: delta, theta, alpha, beta, gamma
- Values: Z-scores (-3 to +3)
- No raw signal needed

## üéµ Music Mapping

The system maps emotions to music parameters:
- **Tempo**: 60-120 BPM based on arousal
- **Key**: C (positive) or A (negative) based on valence
- **Mode**: Major (happy) or Minor (sad)
- **Dynamics**: pp to ff based on intensity
- **Progression**: Contextual chord sequences

## üîß Configuration

Edit `Config` class in `lightweight_demo_api.py`:
```python
class Config:
    SAMPLING_RATE = 256  # Hz
    EEG_CHANNELS = 8
    CACHE_SIZE = 100
    PORT = 8000
```

## üìù Features

‚úÖ **Included:**
- Goertzel algorithm for efficient frequency analysis
- Kalman filtering for noise reduction
- SNR calculation and quality assessment
- Korean text emotion analysis
- YAML mapping loader
- Simple caching
- Unit tests

‚ùå **Not Included (for lightweight):**
- Heavy ML models (BERT, etc.)
- Complex visualizations
- Database persistence
- Full COSMOS architecture
- GPU acceleration

## üö¶ Next Steps

After validating with this demo:

1. **Scale Up**: Deploy full COSMOS system (Option B)
2. **Add Persistence**: PostgreSQL + Redis
3. **Enable GPU**: For 10x performance
4. **Add Monitoring**: Prometheus + Grafana
5. **Expand Models**: BERT, advanced NLP

## üìä Benchmarks

On standard hardware (4 CPU cores, 8GB RAM):
- Text only: ~10ms
- EEG only: ~20ms
- Combined: ~25ms
- Throughput: 50-100 req/s

## ü§ù Support

For issues or questions about this demo, please refer to the main documentation or create an issue in the repository.

 Ï¶âÏãú Ïã§Ìñâ Í∞ÄÎä•Ìïú Í≤ΩÎüâ Îç∞Î™® API ÏôÑÏÑ±

**1. 
ÏòµÏÖò A (Í≤ΩÎüâ Îç∞Î™® API).
5Î∂Ñ ÏïàÏóê Ïã§Ìñâ Í∞ÄÎä•ÌïòÎ©∞,
ÌïµÏã¨ Í∏∞Îä•ÏùÑ Í≤ÄÏ¶ù.

**2. EEG ÏûÖÎ†• ÌòïÏãù**
‚Üí **Îëê Í∞ÄÏßÄ Î™®Îìú Î™®Îëê ÏßÄÏõê:**
- **Raw EEG**: 256 Hz ÏÉòÌîåÎßÅ (128-512 Hz Ï°∞Ï†ï Í∞ÄÎä•)
- **Band Powers**: ÏÇ¨Ï†Ñ Í≥ÑÏÇ∞Îêú 5Í∞ú Î∞¥Îìú ÌååÏõå (delta~gamma)
- Ï±ÑÎÑê Ïàò: 8Ï±ÑÎÑê Í∏∞Î≥∏ (Ï°∞Ï†ï Í∞ÄÎä•)

**3. ÌÖçÏä§Ìä∏ Î∂ÑÏÑù Ìè¨Ìï® Ïó¨Î∂Ä**
‚Üí **Ìè¨Ìï®ÎêòÏóàÏäµÎãàÎã§.** ÌïúÍµ≠Ïñ¥ Ïñ¥ÎØ∏ Í∞êÏßÄ Î∞è Í∏∞Î≥∏ Í∞êÏ†ï ÌÇ§ÏõåÎìú Îß§Ïπ≠ Íµ¨ÌòÑ

**4. Docker Î∞∞Ìè¨ ÌôòÍ≤Ω**
‚Üí **CPU Ï†ÑÏö©, Ïô∏Î∂Ä ÏùòÏ°¥ÏÑ± ÏóÜÏùå.** Redis/Postgres Î∂àÌïÑÏöîÌïú ÎèÖÎ¶Ω Ïã§ÌñâÌòï

3Î∂Ñ Ïã§Ìñâ Í∞ÄÏù¥Îìú

```bash
# 1. ÌååÏùº Ï†ÄÏû•
# lightweight_demo_api.py Ï†ÄÏû•

# 2. ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò (30Ï¥à)
pip install fastapi uvicorn numpy scipy pyyaml

# 3. ÏÑúÎ≤Ñ ÏãúÏûë (5Ï¥à)
python lightweight_demo_api.py

# 4. ÌÖåÏä§Ìä∏ (Î∏åÎùºÏö∞Ï†ÄÏóêÏÑú)
# http://localhost:8000/docs Ï†ëÏÜç
```

Îπ†Î•∏ ÌÖåÏä§Ìä∏

```python
# PythonÏóêÏÑú ÏßÅÏ†ë ÌÖåÏä§Ìä∏
import requests

# ÌÖçÏä§Ìä∏ Í∞êÏ†ï Î∂ÑÏÑù
response = requests.post("http://localhost:8000/analyze", json={
    "text": "Ïò§Îäò Ï†ïÎßê Í∏∞ÏÅòÎÑ§Ïöî!"
})
print(response.json())

# EEG Î∞¥Îìú ÌååÏõåÎ°ú Î∂ÑÏÑù
response = requests.post("http://localhost:8000/analyze", json={
    "eeg_bands": {
        "delta": -0.1, "theta": -0.05, 
        "alpha": 0.35, "beta": 0.25, "gamma": 0.15
    }
})
print(response.json())
```

ÏÑ±Îä• ÌäπÏßï

**Î¶¨ÏÜåÏä§ ÏÇ¨Ïö©:**
- Î©îÎ™®Î¶¨: < 150MB
- CPU: 1 coreÎ°ú Ï∂©Î∂Ñ
- ÏãúÏûë ÏãúÍ∞Ñ: < 2Ï¥à

**Ï≤òÎ¶¨ ÏÑ±Îä•:**
- Îã®Ïùº ÏöîÏ≤≠: 10-30ms
- ÎèôÏãú Ï≤òÎ¶¨: 50-100 req/s
- Ï∫êÏãú Ï†ÅÏ§ë: < 5ms

### Í≤ÄÏ¶ù ÏôÑÎ£å Ìï≠Î™©

- [x] Goertzel ÏïåÍ≥†Î¶¨Ï¶ò (FFTÎ≥¥Îã§ Îπ†Î•∏ Ï£ºÌååÏàò Í≤ÄÏ∂ú)
- [x] Kalman ÌïÑÌÑ∞ÎßÅ (ÎÖ∏Ïù¥Ï¶à Í∞êÏÜå)
- [x] SNR Í≥ÑÏÇ∞ (Ïã†Ìò∏ ÌíàÏßà ÌèâÍ∞Ä)
- [x] ÌïúÍµ≠Ïñ¥ Ïñ¥ÎØ∏ Í∞êÏ†ï Îß§Ìïë
- [x] YAML Íµ¨Ï°∞ ÎÇ¥Ïû•
- [x] Îã®ÏúÑ ÌÖåÏä§Ìä∏ 2Í∞ú
- [x] REST API ÏóîÎìúÌè¨Ïù∏Ìä∏

### Îã§Ïùå Îã®Í≥Ñ Í∂åÏû•ÏÇ¨Ìï≠

**Ïù¥ Îç∞Î™®Î°ú Í≤ÄÏ¶ù ÌõÑ:**

1. **ÏÑ±Îä•Ïù¥ Ï∂©Î∂ÑÌïòÎ©¥** ‚Üí ÌîÑÎ°úÎçïÏÖò Î∞∞Ìè¨
2. **Îçî ÎÜíÏùÄ Ï†ïÌôïÎèÑ ÌïÑÏöî** ‚Üí Option B (Ï†ÑÏ≤¥ COSMOS) Íµ¨Ï∂ï
3. **Î≤§ÏπòÎßàÌÅ¨ ÌïÑÏöî** ‚Üí Option C Ïã§Ìñâ

**ÌôïÏû• ÏãúÎÇòÎ¶¨Ïò§:**
```python
# GPU Ï∂îÍ∞Ä (10x ÏÑ±Îä•)
if torch.cuda.is_available():
    # GPU Í∞ÄÏÜç ÌôúÏÑ±Ìôî
    
# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï∂îÍ∞Ä
if need_persistence:
    # PostgreSQL Ïó∞Í≤∞
    
# Ïã§ÏãúÍ∞Ñ Ïä§Ìä∏Î¶¨Î∞ç
if need_streaming:
    # WebSocket Ï∂îÍ∞Ä
```

Ïù¥ Í≤ΩÎüâ Îç∞Î™®Îäî **Ï¶âÏãú Ïã§Ìñâ Í∞ÄÎä•**ÌïòÎ©∞, ÌïµÏã¨ Í∏∞Îä•ÏùÑ Î™®Îëê Ìè¨Ìï®ÌïòÍ≥† ÏûàÏäµÎãàÎã§. 50-100 req/s Ï≤òÎ¶¨Í∞Ä Í∞ÄÎä•ÌïòÍ≥†, Docker ÏóÜÏù¥ÎèÑ Ïã§ÌñâÎê©ÎãàÎã§. ÌïÑÏöîÏãú Ï†êÏßÑÏ†ÅÏúºÎ°ú Í∏∞Îä•ÏùÑ Ï∂îÍ∞ÄÌï† Ïàò ÏûàÎäî ÌôïÏû• Í∞ÄÎä•Ìïú Íµ¨Ï°∞ÏûÖÎãàÎã§.