#!/usr/bin/env python3
"""
ì •í™•ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
1. ìŒì„±í†µí™” ì²˜ë¦¬ ë° ì‚¬ìš©ì ì±„ì  ì‹œìŠ¤í…œ
2. ì‹œ ë¶„ì„ ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ë¹„êµ
"""

import numpy as np
import pandas as pd
import speech_recognition as sr
import soundfile as sf
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import threading

# ìœ„ì—ì„œ ì •ì˜í•œ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ import
# from enhanced_emotion_engine import IntegratedEmotionAnalysisSystem

# =============================================================================
# 1. ìŒì„±í†µí™” ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
# =============================================================================

@dataclass
class AudioAnalysisResult:
    """ìŒì„± ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    audio_file: str
    transcribed_text: str
    emotion_vector: np.ndarray
    processing_time: float
    confidence_score: float
    user_rating: Optional[int] = None
    user_feedback: Optional[str] = None

class VoiceEmotionTestSystem:
    """
    ìŒì„±í†µí™” ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
    - ìŒì„± íŒŒì¼ ì²˜ë¦¬
    - í…ìŠ¤íŠ¸ ë³€í™˜
    - ê°ì • ë¶„ì„
    - ì‚¬ìš©ì ì±„ì  ì¸í„°í˜ì´ìŠ¤
    """
    
    def __init__(self, emotion_system):
        self.emotion_system = emotion_system
        self.recognizer = sr.Recognizer()
        self.test_results = []
        
        # ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹
        self.supported_formats = ['.wav', '.flac', '.aiff', '.mp3', '.ogg']
        
    def process_audio_file(self, audio_path: str, language: str = 'ko-KR') -> AudioAnalysisResult:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        print(f"\n{'='*20} ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ {'='*20}")
        print(f"íŒŒì¼: {audio_path}")
        
        start_time = time.time()
        
        try:
            # 1. ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            print("1. ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            transcribed_text = self._speech_to_text(audio_path, language)
            print(f"   ë³€í™˜ëœ í…ìŠ¤íŠ¸: {transcribed_text}")
            
            # 2. ê°ì • ë¶„ì„ ì‹¤í–‰
            print("2. ê°ì • ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            emotion_analysis = self.emotion_system.analyze_emotion(transcribed_text)
            emotion_vector = np.array(emotion_analysis['emotion_vector_28d'])
            confidence = np.mean(emotion_analysis['confidence_scores'])
            
            processing_time = time.time() - start_time
            
            # 3. ê²°ê³¼ ê°ì²´ ìƒì„±
            result = AudioAnalysisResult(
                audio_file=audio_path,
                transcribed_text=transcribed_text,
                emotion_vector=emotion_vector,
                processing_time=processing_time,
                confidence_score=confidence
            )
            
            print(f"3. ì²˜ë¦¬ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {processing_time:.2f}ì´ˆ)")
            print(f"   ì‹ ë¢°ë„: {confidence:.3f}")
            
            return result
            
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return AudioAnalysisResult(
                audio_file=audio_path,
                transcribed_text="[ë³€í™˜ ì‹¤íŒ¨]",
                emotion_vector=np.zeros(28),
                processing_time=time.time() - start_time,
                confidence_score=0.0
            )
    
    def _speech_to_text(self, audio_path: str, language: str) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            with sr.AudioFile(audio_path) as source:
                # ì£¼ë³€ ì†ŒìŒ ì œê±°
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                # ì˜¤ë””ì˜¤ ë°ì´í„° ìº¡ì²˜
                audio_data = self.recognizer.record(source)
            
            # Google Speech Recognition API ì‚¬ìš©
            text = self.recognizer.recognize_google(audio_data, language=language)
            
            return text
            
        except sr.UnknownValueError:
            return "[ìŒì„± ì¸ì‹ ë¶ˆê°€]"
        except sr.RequestError as e:
            return f"[API ì˜¤ë¥˜: {e}]"
        except Exception as e:
            return f"[ì²˜ë¦¬ ì˜¤ë¥˜: {e}]"
    
    def create_user_rating_interface(self, result: AudioAnalysisResult) -> Dict:
        """ì‚¬ìš©ì ì±„ì  ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        
        user_feedback = {}
        
        def submit_rating():
            try:
                # ì ìˆ˜ ìˆ˜ì§‘
                accuracy_rating = accuracy_scale.get()
                emotion_rating = emotion_scale.get()
                
                # ê°ì • ì„ íƒ ìˆ˜ì§‘
                selected_emotions = []
                for emotion, var in emotion_vars.items():
                    if var.get():
                        selected_emotions.append(emotion)
                
                # í…ìŠ¤íŠ¸ í”¼ë“œë°± ìˆ˜ì§‘
                feedback_text = feedback_entry.get("1.0", tk.END).strip()
                
                user_feedback.update({
                    'accuracy_rating': accuracy_rating,
                    'emotion_appropriateness': emotion_rating,
                    'correct_emotions': selected_emotions,
                    'feedback_text': feedback_text,
                    'transcription_correct': transcription_var.get()
                })
                
                root.quit()
                root.destroy()
                
            except Exception as e:
                messagebox.showerror("ì˜¤ë¥˜", f"í‰ê°€ ì œì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # GUI ìƒì„±
        root = tk.Tk()
        root.title("ìŒì„± ê°ì • ë¶„ì„ ê²°ê³¼ í‰ê°€")
        root.geometry("800x700")
        
        # ë©”ì¸ í”„ë ˆì„
        main_frame = ttk.Frame(root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # 1. ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        result_frame = ttk.LabelFrame(main_frame, text="ë¶„ì„ ê²°ê³¼", padding="10")
        result_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(result_frame, text=f"ì˜¤ë””ì˜¤ íŒŒì¼: {Path(result.audio_file).name}").grid(row=0, column=0, sticky=tk.W)
        ttk.Label(result_frame, text=f"ë³€í™˜ëœ í…ìŠ¤íŠ¸: {result.transcribed_text}").grid(row=1, column=0, sticky=tk.W)
        ttk.Label(result_frame, text=f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ").grid(row=2, column=0, sticky=tk.W)
        ttk.Label(result_frame, text=f"ì‹œìŠ¤í…œ ì‹ ë¢°ë„: {result.confidence_score:.3f}").grid(row=3, column=0, sticky=tk.W)
        
        # 2. í…ìŠ¤íŠ¸ ë³€í™˜ ì •í™•ë„ í‰ê°€
        transcription_frame = ttk.LabelFrame(main_frame, text="í…ìŠ¤íŠ¸ ë³€í™˜ í‰ê°€", padding="10")
        transcription_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        transcription_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(transcription_frame, text="í…ìŠ¤íŠ¸ ë³€í™˜ì´ ì •í™•í•¨", variable=transcription_var).grid(row=0, column=0, sticky=tk.W)
        
        # 3. ê°ì • ë¶„ì„ ì •í™•ë„ í‰ê°€
        accuracy_frame = ttk.LabelFrame(main_frame, text="ê°ì • ë¶„ì„ ì •í™•ë„ (1-10ì )", padding="10")
        accuracy_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(accuracy_frame, text="ì „ì²´ì ì¸ ê°ì • ë¶„ì„ ì •í™•ë„:").grid(row=0, column=0, sticky=tk.W)
        accuracy_scale = tk.Scale(accuracy_frame, from_=1, to=10, orient=tk.HORIZONTAL)
        accuracy_scale.set(5)
        accuracy_scale.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # 4. ê°ì • ì ì ˆì„± í‰ê°€
        emotion_frame = ttk.LabelFrame(main_frame, text="ê°ì • í‘œí˜„ ì ì ˆì„± (1-10ì )", padding="10")
        emotion_frame.grid(row=2, column=1, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(emotion_frame, text="ê°ì • ë²¡í„°ì˜ ì ì ˆì„±:").grid(row=0, column=0, sticky=tk.W)
        emotion_scale = tk.Scale(emotion_frame, from_=1, to=10, orient=tk.HORIZONTAL)
        emotion_scale.set(5)
        emotion_scale.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # 5. ì˜¬ë°”ë¥¸ ê°ì • ì„ íƒ
        correct_emotion_frame = ttk.LabelFrame(main_frame, text="ì‹¤ì œ ê°ì • ì„ íƒ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", padding="10")
        correct_emotion_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        emotions = ['ê¸°ì¨', 'ìŠ¬í””', 'ë¶„ë…¸', 'ë‘ë ¤ì›€', 'ë†€ëŒ', 'í˜ì˜¤', 'ì¤‘ë¦½', 'ë³µí•©ê°ì •', 'ê·¸ë¦¬ì›€', 'ì•„ë ¨í•¨', 'ë¿Œë“¯í•¨']
        emotion_vars = {}
        
        for i, emotion in enumerate(emotions):
            var = tk.BooleanVar()
            emotion_vars[emotion] = var
            ttk.Checkbutton(correct_emotion_frame, text=emotion, variable=var).grid(row=i//4, column=i%4, sticky=tk.W, padx=5)
        
        # 6. ììœ  í”¼ë“œë°±
        feedback_frame = ttk.LabelFrame(main_frame, text="ì¶”ê°€ í”¼ë“œë°±", padding="10")
        feedback_frame.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        ttk.Label(feedback_frame, text="ê°œì„ ì ì´ë‚˜ ì¶”ê°€ ì˜ê²¬:").grid(row=0, column=0, sticky=tk.W)
        feedback_entry = tk.Text(feedback_frame, height=4, width=60)
        feedback_entry.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E))
        
        # 7. ì œì¶œ ë²„íŠ¼
        submit_btn = ttk.Button(main_frame, text="í‰ê°€ ì œì¶œ", command=submit_rating)
        submit_btn.grid(row=5, column=0, columnspan=2, pady=10)
        
        # GUI ì‹¤í–‰
        root.mainloop()
        
        return user_feedback
    
    def run_audio_test_batch(self, audio_directory: str) -> List[AudioAnalysisResult]:
        """ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        
        audio_dir = Path(audio_directory)
        audio_files = []
        
        # ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
        for format_ext in self.supported_formats:
            audio_files.extend(audio_dir.glob(f"*{format_ext}"))
        
        print(f"\nì´ {len(audio_files)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ë°œê²¬")
        
        results = []
        for i, audio_file in enumerate(audio_files, 1):
            print(f"\n[{i}/{len(audio_files)}] ì²˜ë¦¬ ì¤‘: {audio_file.name}")
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
            result = self.process_audio_file(str(audio_file))
            
            # ì‚¬ìš©ì í‰ê°€ ë°›ê¸°
            print("ì‚¬ìš©ì í‰ê°€ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
            user_feedback = self.create_user_rating_interface(result)
            
            # í”¼ë“œë°± ì¶”ê°€
            result.user_rating = user_feedback.get('accuracy_rating', 0)
            result.user_feedback = user_feedback
            
            results.append(result)
            
            # ì¤‘ê°„ ì €ì¥
            self._save_partial_results(results, audio_directory)
        
        print(f"\nëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        return results
    
    def _save_partial_results(self, results: List[AudioAnalysisResult], output_dir: str):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        
        output_path = Path(output_dir) / "audio_test_results.json"
        
        results_data = []
        for result in results:
            results_data.append({
                'audio_file': result.audio_file,
                'transcribed_text': result.transcribed_text,
                'emotion_vector': result.emotion_vector.tolist(),
                'processing_time': result.processing_time,
                'confidence_score': result.confidence_score,
                'user_rating': result.user_rating,
                'user_feedback': result.user_feedback
            })
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, ensure_ascii=False, indent=2)
        
        print(f"ì¤‘ê°„ ê²°ê³¼ ì €ì¥: {output_path}")

# =============================================================================
# 2. ì‹œ ë¶„ì„ ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ë¹„êµ í…ŒìŠ¤íŠ¸
# =============================================================================

class PoetryAnalysisComparison:
    """
    ì‹œ ë¶„ì„ ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ë¹„êµ í…ŒìŠ¤íŠ¸
    - ì‹œ ê°ì • ë¶„ì„
    - ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê²°ê³¼ ë¹„êµ
    - ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    """
    
    def __init__(self, emotion_system, baseline_systems: Optional[Dict] = None):
        self.emotion_system = emotion_system
        self.baseline_systems = baseline_systems or {}
        self.poetry_results = []
        
        # í…ŒìŠ¤íŠ¸ìš© ì‹œ ëª¨ìŒ
        self.test_poems = self._load_test_poems()
        
    def _load_test_poems(self) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ìš© ì‹œ ë°ì´í„° ë¡œë“œ"""
        
        return [
            {
                'title': 'ì§„ë‹¬ë˜ê½ƒ',
                'author': 'ê¹€ì†Œì›”',
                'text': '''ë‚˜ ë³´ê¸°ê°€ ì—­ê²¨ì›Œ
ê°€ì‹¤ ë•Œì—ëŠ”
ë§ì—†ì´ ê³ ì´ ë³´ë‚´ ë“œë¦¬ìš°ë¦¬ë‹¤

ì˜ë³€ì— ì•½ì‚°
ì§„ë‹¬ë˜ê½ƒ
ì•„ë¦„ ë”°ë‹¤ ê°€ì‹¤ ê¸¸ì— ë¿Œë¦¬ìš°ë¦¬ë‹¤

ê°€ì‹œëŠ” ê±¸ìŒê±¸ìŒ
ë†“ì¸ ê·¸ ê½ƒì„
ì‚¬ë¿íˆ ì¦ˆë ¤ë°Ÿê³  ê°€ì‹œì˜µì†Œì„œ

ë‚˜ ë³´ê¸°ê°€ ì—­ê²¨ì›Œ
ê°€ì‹¤ ë•Œì—ëŠ”
ì£½ì–´ë„ ì•„ë‹ˆ ëˆˆë¬¼ í˜ë¦¬ìš°ë¦¬ë‹¤''',
                'expected_emotions': ['ìŠ¬í””', 'ì‚¬ë‘', 'ì´ë³„', 'ì²´ë…'],
                'complexity_level': 'high'
            },
            {
                'title': 'ë‹˜ì˜ ì¹¨ë¬µ',
                'author': 'í•œìš©ìš´', 
                'text': '''ë‹˜ì€ ê°”ìŠµë‹ˆë‹¤. ì•„ì•„, ì‚¬ë‘í•˜ëŠ” ë‚˜ì˜ ë‹˜ì€ ê°”ìŠµë‹ˆë‹¤.
í‘¸ë¥¸ ì‚°ë¹›ì„ ê¹¨ëœ¨ë¦¬ë©° ë‹¨í’ì ê°™ì€ ì‚¬ë‘ì„ ì°¨ê³ 
ì •ë“  ë‹˜ì€ ê°”ìŠµë‹ˆë‹¤.

í™©ê¸ˆì˜ ê½ƒê°™ì´ êµ³ê³  ë¹›ë‚˜ë˜ ì˜› ë§¹ì„¸ëŠ” ì°¨ë””ì°¬ í‹°ëŒì´ ë˜ì–´ì„œ
í•œìˆ¨ì˜ ë¯¸í’ì— ë‚ ì•„ê°”ìŠµë‹ˆë‹¤.

ë‚ ì¹´ë¡œìš´ ì²« í‚¤ìŠ¤ì˜ ì¶”ì–µì€ ë‚˜ì˜ ìš´ëª…ì˜ ì§€ì¹¨ì„ ëŒë ¤ ë†“ê³ ,
ë’·ê±¸ìŒì³ì„œ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤.''',
                'expected_emotions': ['ê·¸ë¦¬ì›€', 'ìŠ¬í””', 'ì‚¬ë‘', 'ìƒì‹¤ê°'],
                'complexity_level': 'high'
            },
            {
                'title': 'ì—„ë§ˆì•¼ ëˆ„ë‚˜ì•¼',
                'author': 'ê¹€ì†Œì›”',
                'text': '''ì—„ë§ˆì•¼ ëˆ„ë‚˜ì•¼ ê°•ë³€ ì‚´ì.
ë“¤ì—ëŠ” ë°˜ì§ì´ëŠ” ê¸ˆëª¨ë˜ë¹›
ë¬¼ì—ëŠ” ì—°ê½ƒì´ ë–  ìˆê³ ,
ìš°ë¦¬ê°€ ë†€ë˜ ê·¸ ê°•ë³€ ì‚´ì.

ì—„ë§ˆì•¼ ëˆ„ë‚˜ì•¼ ê°•ë³€ ì‚´ì.
ê½ƒì€ ì¢‹ì„ëŒ€ë¡œ í”¼ì–´ ìˆê³ ,
ë»ê¾¸ê¸°ëŠ” ì• íƒ€ê²Œ ìš¸ì–´ ì˜ˆì˜ë‹¤.
ìš°ë¦¬ê°€ ë†€ë˜ ê·¸ ê°•ë³€ ì‚´ì.''',
                'expected_emotions': ['ê·¸ë¦¬ì›€', 'í–¥ìˆ˜', 'í‰ì˜¨', 'ê·¸ë¦¬ì›€'],
                'complexity_level': 'medium'
            },
            {
                'title': 'ì²­í¬ë„',
                'author': 'ì´ìœ¡ì‚¬',
                'text': '''ë‚´ ê³ ì¥ ì¹ ì›”ì€
ì²­í¬ë„ê°€ ìµì–´ ê°€ëŠ” ì‹œì ˆ

ì´ ë§ˆì„ ì „ì„¤ì´ ì£¼ì €ë¦¬ì£¼ì €ë¦¬ ì—´ë¦¬ê³ 
ë¨¼ ë° í•˜ëŠ˜ì´ ê¿ˆê¾¸ë©° ì•Œì•Œì´ ë“¤ì–´ì™€ ë°•í˜€

í•˜ëŠ˜ ë°‘ í‘¸ë¥¸ ë°”ë‹¤ê°€ ê°€ìŠ´ì„ ì—´ê³ 
í° ë›ë‹¨ë°°ê°€ ê³±ê²Œ ë°€ë ¤ì„œ ì˜¤ë©´

ëŠ” ë°±ì¡°ì²˜ëŸ¼ ëª©ì´ ê¸¸ì–´ì„œ ë˜ê³ 
ì°¨ë§ˆ ë–¨ì¹˜ì§€ ëª»í•  í•˜ë‚˜ì˜ ì¸ì—°ì¸ ì–‘ 
ê°€ìŠ´ì— ì¡°ìœ¼ëŠ” ê·¸ë¦¬ì›€ì´ ìˆë‹¤''',
                'expected_emotions': ['ê·¸ë¦¬ì›€', 'í–¥ìˆ˜', 'í¬ë§', 'ì•„ë ¨í•¨'],
                'complexity_level': 'high'
            }
        ]
    
    def analyze_poem_comprehensive(self, poem_data: Dict) -> Dict:
        """ì‹œì— ëŒ€í•œ ì¢…í•©ì  ë¶„ì„"""
        
        print(f"\n{'='*20} ì‹œ ë¶„ì„: {poem_data['title']} {'='*20}")
        
        # 1. ìš°ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ë¶„ì„
        our_analysis = self.emotion_system.analyze_emotion(poem_data['text'])
        
        # 2. ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ ë¹„êµ (ìˆëŠ” ê²½ìš°)
        baseline_results = {}
        for system_name, system in self.baseline_systems.items():
            try:
                baseline_results[system_name] = system.analyze(poem_data['text'])
            except Exception as e:
                print(f"ê¸°ì¡´ ì‹œìŠ¤í…œ {system_name} ë¶„ì„ ì‹¤íŒ¨: {e}")
                baseline_results[system_name] = None
        
        # 3. ê°ì • ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        emotion_match_score = self._calculate_emotion_match_score(
            our_analysis, poem_data['expected_emotions']
        )
        
        # 4. ë³µì¡ë„ ì ì ˆì„± í‰ê°€
        complexity_score = self._evaluate_complexity_appropriateness(
            our_analysis, poem_data['complexity_level']
        )
        
        result = {
            'poem_info': poem_data,
            'our_analysis': our_analysis,
            'baseline_results': baseline_results,
            'evaluation_scores': {
                'emotion_match_score': emotion_match_score,
                'complexity_score': complexity_score,
                'overall_score': (emotion_match_score + complexity_score) / 2
            },
            'analysis_timestamp': time.time()
        }
        
        self.poetry_results.append(result)
        
        return result
    
    def _calculate_emotion_match_score(self, analysis_result: Dict, expected_emotions: List[str]) -> float:
        """ì˜ˆìƒ ê°ì •ê³¼ì˜ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        
        emotion_vector = np.array(analysis_result['emotion_vector_28d'])
        
        # ê°ì • ë²¡í„°ì—ì„œ ì£¼ìš” ê°ì • ì¶”ì¶œ (ìƒìœ„ ëª‡ ê°œ ì°¨ì›ì˜ ê°’ ê¸°ë°˜)
        top_emotion_indices = np.argsort(np.abs(emotion_vector))[-5:]  # ìƒìœ„ 5ê°œ
        
        # ê°„ë‹¨í•œ ë§¤ì¹­ ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë§¤í•‘ í•„ìš”)
        emotion_mapping = {
            'ìŠ¬í””': [0, 1, 7],     # ì „ì²´ í†¤, ë‹¨ì–´ ê°ì •ê°€, ìµœì¢… ê°ì • ìƒíƒœ
            'ê·¸ë¦¬ì›€': [2, 10, 14],  # í˜•íƒœì†Œ ê°•ë„, ë¬¸í™”ì  ë‰˜ì•™ìŠ¤, ëª¨í˜¸ì„±
            'ì‚¬ë‘': [8, 11],       # ê°ì„± ìˆ˜ì¤€, ì •ì¤‘í•¨
            'ê¸°ì¨': [1, 8, 9],     # ë‹¨ì–´ ê°ì •ê°€, ê°ì„±, ë³µì¡ì„±
            'í–¥ìˆ˜': [10, 14, 15],  # ë¬¸í™”ì  ë‰˜ì•™ìŠ¤, ëª¨í˜¸ì„±, ì»¨í…ìŠ¤íŠ¸ ì˜ì¡´ì„±
            'ì•„ë ¨í•¨': [14, 15, 26] # ëª¨í˜¸ì„±, ì»¨í…ìŠ¤íŠ¸ ì˜ì¡´ì„±, ë¶ˆí™•ì‹¤ì„±
        }
        
        match_score = 0.0
        for expected_emotion in expected_emotions:
            if expected_emotion in emotion_mapping:
                relevant_dims = emotion_mapping[expected_emotion]
                avg_intensity = np.mean([abs(emotion_vector[i]) for i in relevant_dims])
                match_score += avg_intensity
        
        return min(match_score / len(expected_emotions), 1.0)
    
    def _evaluate_complexity_appropriateness(self, analysis_result: Dict, expected_complexity: str) -> float:
        """ë³µì¡ë„ ì ì ˆì„± í‰ê°€"""
        
        emotion_vector = np.array(analysis_result['emotion_vector_28d'])
        
        # ë³µì¡ë„ ê´€ë ¨ ì°¨ì›ë“¤ (9-16ì°¨ì› ì£¼ë¡œ)
        complexity_dims = [9, 10, 13, 14, 15]  # ê°ì •ë³µì¡ë„, ë¬¸í™”ì ë‰˜ì•™ìŠ¤, ì •êµí•¨, ëª¨í˜¸ì„±, ì»¨í…ìŠ¤íŠ¸ì˜ì¡´ì„±
        measured_complexity = np.mean([emotion_vector[i] for i in complexity_dims])
        
        # ì˜ˆìƒ ë³µì¡ë„ì™€ ë¹„êµ
        complexity_targets = {
            'low': 0.3,
            'medium': 0.6,
            'high': 0.9
        }
        
        target_complexity = complexity_targets.get(expected_complexity, 0.6)
        complexity_diff = abs(measured_complexity - target_complexity)
        
        # ì°¨ì´ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        return max(0, 1.0 - complexity_diff * 2)
    
    def run_poetry_comparison_test(self) -> Dict:
        """ì‹œ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        print(f"\n{'='*20} ì‹œ ë¶„ì„ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘ {'='*20}")
        
        all_results = []
        
        for poem in self.test_poems:
            result = self.analyze_poem_comprehensive(poem)
            all_results.append(result)
            
            # ê²°ê³¼ ì¶œë ¥
            self._print_poem_analysis_result(result)
        
        # ì „ì²´ ì„±ëŠ¥ ìš”ì•½
        summary = self._calculate_overall_performance(all_results)
        
        return {
            'individual_results': all_results,
            'performance_summary': summary,
            'test_metadata': {
                'total_poems_tested': len(self.test_poems),
                'baseline_systems_used': list(self.baseline_systems.keys()),
                'test_timestamp': time.time()
            }
        }
    
    def _print_poem_analysis_result(self, result: Dict):
        """ì‹œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        
        poem_info = result['poem_info']
        scores = result['evaluation_scores']
        
        print(f"\nğŸ“ {poem_info['title']} - {poem_info['author']}")
        print(f"   ì˜ˆìƒ ê°ì •: {', '.join(poem_info['expected_emotions'])}")
        print(f"   ì˜ˆìƒ ë³µì¡ë„: {poem_info['complexity_level']}")
        print(f"   ğŸ“Š í‰ê°€ ì ìˆ˜:")
        print(f"     - ê°ì • ë§¤ì¹­: {scores['emotion_match_score']:.3f}")
        print(f"     - ë³µì¡ë„ ì ì ˆì„±: {scores['complexity_score']:.3f}")
        print(f"     - ì „ì²´ ì ìˆ˜: {scores['overall_score']:.3f}")
        
        # ê°ì • ë²¡í„° ìš”ì•½
        our_vector = np.array(result['our_analysis']['emotion_vector_28d'])
        print(f"   ğŸ¯ ì£¼ìš” íŠ¹ì„±:")
        print(f"     - ì „ì²´ ê°ì • í†¤: {our_vector[0]:.3f}")
        print(f"     - ê°ì • ë³µì¡ë„: {our_vector[9]:.3f}")
        print(f"     - ë¬¸í™”ì  ë‰˜ì•™ìŠ¤: {our_vector[10]:.3f}")
        print(f"     - ê°ì • ëª¨í˜¸ì„±: {our_vector[14]:.3f}")
    
    def _calculate_overall_performance(self, results: List[Dict]) -> Dict:
        """ì „ì²´ ì„±ëŠ¥ ê³„ì‚°"""
        
        emotion_scores = [r['evaluation_scores']['emotion_match_score'] for r in results]
        complexity_scores = [r['evaluation_scores']['complexity_score'] for r in results]
        overall_scores = [r['evaluation_scores']['overall_score'] for r in results]
        
        summary = {
            'average_emotion_match': np.mean(emotion_scores),
            'average_complexity_appropriateness': np.mean(complexity_scores),
            'average_overall_score': np.mean(overall_scores),
            'score_std': np.std(overall_scores),
            'best_performing_poem': max(results, key=lambda x: x['evaluation_scores']['overall_score'])['poem_info']['title'],
            'worst_performing_poem': min(results, key=lambda x: x['evaluation_scores']['overall_score'])['poem_info']['title']
        }
        
        print(f"\n{'='*20} ì „ì²´ ì„±ëŠ¥ ìš”ì•½ {'='*20}")
        print(f"í‰ê·  ê°ì • ë§¤ì¹­ ì ìˆ˜: {summary['average_emotion_match']:.3f}")
        print(f"í‰ê·  ë³µì¡ë„ ì ì ˆì„±: {summary['average_complexity_appropriateness']:.3f}")
        print(f"í‰ê·  ì „ì²´ ì ìˆ˜: {summary['average_overall_score']:.3f}")
        print(f"ì ìˆ˜ í‘œì¤€í¸ì°¨: {summary['score_std']:.3f}")
        print(f"ìµœê³  ì„±ëŠ¥ ì‹œ: {summary['best_performing_poem']}")
        print(f"ìµœì € ì„±ëŠ¥ ì‹œ: {summary['worst_performing_poem']}")
        
        return summary
    
    def generate_comparison_report(self, test_results: Dict, output_path: str):
        """ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        
        # 1. ì„±ëŠ¥ ì ìˆ˜ ì‹œê°í™”
        scores_data = []
        for result in test_results['individual_results']:
            scores_data.append({
                'poem': result['poem_info']['title'],
                'emotion_match': result['evaluation_scores']['emotion_match_score'],
                'complexity': result['evaluation_scores']['complexity_score'],
                'overall': result['evaluation_scores']['overall_score']
            })
        
        df_scores = pd.DataFrame(scores_data)
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # ì „ì²´ ì ìˆ˜ ë°” ì°¨íŠ¸
        axes[0, 0].bar(df_scores['poem'], df_scores['overall'])
        axes[0, 0].set_title('ì „ì²´ ì ìˆ˜ (ì‹œë³„)')
        axes[0, 0].set_ylabel('ì ìˆ˜')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # ê°ì • ë§¤ì¹­ vs ë³µì¡ë„ ì‚°ì ë„
        axes[0, 1].scatter(df_scores['emotion_match'], df_scores['complexity'])
        for i, poem in enumerate(df_scores['poem']):
            axes[0, 1].annotate(poem, (df_scores['emotion_match'][i], df_scores['complexity'][i]))
        axes[0, 1].set_xlabel('ê°ì • ë§¤ì¹­ ì ìˆ˜')
        axes[0, 1].set_ylabel('ë³µì¡ë„ ì ì ˆì„±')
        axes[0, 1].set_title('ê°ì • ë§¤ì¹­ vs ë³µì¡ë„')
        
        # ê°ì • ë²¡í„° íˆíŠ¸ë§µ (ì²« ë²ˆì§¸ ì‹œ)
        first_result = test_results['individual_results'][0]
        emotion_vector = np.array(first_result['our_analysis']['emotion_vector_28d']).reshape(4, 7)
        im = axes[1, 0].imshow(emotion_vector, cmap='coolwarm', aspect='auto')
        axes[1, 0].set_title(f'ê°ì • ë²¡í„° íˆíŠ¸ë§µ: {first_result["poem_info"]["title"]}')
        plt.colorbar(im, ax=axes[1, 0])
        
        # ì„±ëŠ¥ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
        axes[1, 1].hist(df_scores['overall'], bins=10, alpha=0.7)
        axes[1, 1].axvline(np.mean(df_scores['overall']), color='red', linestyle='--', label='í‰ê· ')
        axes[1, 1].set_xlabel('ì „ì²´ ì ìˆ˜')
        axes[1, 1].set_ylabel('ë¹ˆë„')
        axes[1, 1].set_title('ì„±ëŠ¥ ì ìˆ˜ ë¶„í¬')
        axes[1, 1].legend()
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: {output_path}")

# =============================================================================
# 3. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
# =============================================================================

class AccuracyTestRunner:
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""
    
    def __init__(self, emotion_system):
        self.emotion_system = emotion_system
        self.voice_tester = VoiceEmotionTestSystem(emotion_system)
        self.poetry_tester = PoetryAnalysisComparison(emotion_system)
        
    def run_full_accuracy_test(self, audio_dir: Optional[str] = None, 
                             output_dir: str = "./test_results"):
        """ì „ì²´ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        print(f"\n{'='*50}")
        print("ğŸ§  ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"{'='*50}")
        
        all_results = {}
        
        # 1. ì‹œ ë¶„ì„ í…ŒìŠ¤íŠ¸ (í•­ìƒ ì‹¤í–‰)
        print("\n1ï¸âƒ£ ì‹œ ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
        poetry_results = self.poetry_tester.run_poetry_comparison_test()
        all_results['poetry_test'] = poetry_results
        
        # ì‹œê°í™” ë³´ê³ ì„œ ìƒì„±
        poetry_report_path = output_path / "poetry_analysis_report.png"
        self.poetry_tester.generate_comparison_report(poetry_results, str(poetry_report_path))
        
        # 2. ìŒì„± ë¶„ì„ í…ŒìŠ¤íŠ¸ (ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬ê°€ ì œê³µëœ ê²½ìš°)
        if audio_dir and Path(audio_dir).exists():
            print("\n2ï¸âƒ£ ìŒì„± ë¶„ì„ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
            voice_results = self.voice_tester.run_audio_test_batch(audio_dir)
            all_results['voice_test'] = voice_results
        else:
            print("\n2ï¸âƒ£ ìŒì„± ë¶„ì„ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬ ì—†ìŒ)")
        
        # 3. ì „ì²´ ê²°ê³¼ ì €ì¥
        results_file = output_path / "full_accuracy_test_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™”
            json_serializable_results = self._make_json_serializable(all_results)
            json.dump(json_serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"ğŸ“Š ìƒì„¸ ê²°ê³¼: {results_file}")
        
        return all_results
    
    def _make_json_serializable(self, obj):
        """numpy ë°°ì—´ ë“±ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜"""
        if isinstance(obj, dict):
            return {key: self._make_json_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        else:
            return obj

# =============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ ì •í™•ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì‹¤ì œ ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´ í•„ìš”)
    # emotion_system = IntegratedEmotionAnalysisSystem()
    
    # ë”ë¯¸ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    class DummyEmotionSystem:
        def analyze_emotion(self, text):
            return {
                'emotion_vector_28d': np.random.rand(28).tolist(),
                'confidence_scores': np.random.rand(5).tolist()
            }
    
    emotion_system = DummyEmotionSystem()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸° ìƒì„±
    test_runner = AccuracyTestRunner(emotion_system)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    # audio_directory = input("ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê±´ë„ˆë›°ë ¤ë©´ Enter): ").strip()
    # if not audio_directory:
    #     audio_directory = None
    
    results = test_runner.run_full_accuracy_test(
        audio_dir=None,  # ì˜¤ë””ì˜¤ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€
        output_dir="./test_results"
    )
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()